"""
ì• í”Œë¦¬ì¼€ì´ì…˜ ì „ë°˜ì˜ ì„¤ì •ê°’ ê´€ë¦¬

í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¡œë“œí•˜ê±°ë‚˜ ê¸°ë³¸ê°’ì„ ì œê³µí•˜ëŠ” ì„¤ì • ì¤‘ì•™í™” ëª¨ë“ˆ
"""

import os
from pathlib import Path


# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ
PROJECT_ROOT = Path(__file__).parent.parent

# LLM ê´€ë ¨ ì„¤ì •
LLM_PROVIDER = os.getenv("LLM_PROVIDER", "openai")
LLM_MODEL_NAME = os.getenv("LLM_MODEL_NAME", "gpt-4o")
LLM_TEMPERATURE = float(os.getenv("LLM_TEMPERATURE", "0.7"))

# OpenAI API ì„¤ì •
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ì›Œí¬í”Œë¡œìš° ì„¤ì •
WORKFLOW_FILE_PATH = str(PROJECT_ROOT / "resources" / "workflow_graph.json")

# RAG ì‹œìŠ¤í…œ ì„¤ì •
CODE_SNIPPETS_DIR = str(PROJECT_ROOT / "resources" / "code_snippets")
RAG_INDEX_PATH = str(PROJECT_ROOT / "resources" / "rag_index" / "code_snippets.index")
EMBEDDING_MODEL_NAME = os.getenv("EMBEDDING_MODEL_NAME", "text-embedding-ada-002")

# í”„ë¡¬í”„íŠ¸ ì„¤ì •
PROMPT_TEMPLATES_DIR = str(PROJECT_ROOT / "llm_services" / "prompts")

# ë°ì´í„° ê²½ë¡œ ì„¤ì •
INPUT_DATA_DEFAULT_DIR = str(PROJECT_ROOT / "input_data")
OUTPUT_RESULTS_DIR = str(PROJECT_ROOT / "output_results")

# ë¡œê¹… ì„¤ì •
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO")

# ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ ì„¤ì •
MAX_HISTORY_ITEMS = int(os.getenv("MAX_HISTORY_ITEMS", "20"))
SUMMARIZATION_TRIGGER_COUNT = int(os.getenv("SUMMARIZATION_TRIGGER_COUNT", "10"))
CONTEXT_TOKEN_LIMIT = int(os.getenv("CONTEXT_TOKEN_LIMIT", "3000"))

# ì½”ë“œ ì‹¤í–‰ ì„¤ì •
CODE_EXECUTION_TIMEOUT = int(os.getenv("CODE_EXECUTION_TIMEOUT", "30"))
SAFE_CODE_EXECUTION = os.getenv("SAFE_CODE_EXECUTION", "true").lower() == "true"

# ë³´ê³ ì„œ ì„¤ì •
REPORT_FORMAT = os.getenv("REPORT_FORMAT", "md")  # "md", "html", "pdf"

# ê°œë°œ/í”„ë¡œë•ì…˜ ëª¨ë“œ
DEBUG_MODE = os.getenv("DEBUG_MODE", "false").lower() == "true"

# í•„ìˆ˜ ë””ë ‰í† ë¦¬ ìƒì„± í•¨ìˆ˜
def ensure_directories():
    """í•„ìš”í•œ ë””ë ‰í† ë¦¬ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    directories_to_create = [
        INPUT_DATA_DEFAULT_DIR,
        OUTPUT_RESULTS_DIR,
        CODE_SNIPPETS_DIR,
        "logs",  # ë¡œê·¸ ë””ë ‰í† ë¦¬
        "config",
        "llm_services/prompts",
        RAG_INDEX_PATH
    ]
    
    for directory in directories_to_create:
        if directory and not os.path.exists(directory):
            try:
                os.makedirs(directory, exist_ok=True)
                print(f"ğŸ“ ë””ë ‰í† ë¦¬ ìƒì„±: {directory}")
            except Exception as e:
                print(f"âš ï¸  ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨ ({directory}): {e}")

# ì„¤ì • ê²€ì¦ í•¨ìˆ˜
def validate_settings():
    """í™˜ê²½ ì„¤ì • ê²€ì¦"""
    errors = []
    
    # LLM ì œê³µì í™•ì¸
    if LLM_PROVIDER.lower() != "openai":
        errors.append(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” LLM ì œê³µì: {LLM_PROVIDER}. 'openai'ë§Œ ì§€ì›ë©ë‹ˆë‹¤.")
    
    # OpenAI API í‚¤ í™•ì¸
    if LLM_PROVIDER.lower() == "openai":
        if not os.getenv("OPENAI_API_KEY"):
            errors.append("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    # í•„ìˆ˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ ê²€ì¦
    required_dirs = [
        WORKFLOW_FILE_PATH,
        CODE_SNIPPETS_DIR,
        INPUT_DATA_DEFAULT_DIR,
        OUTPUT_RESULTS_DIR
    ]
    
    for dir_path in required_dirs:
        if not os.path.exists(os.path.dirname(dir_path)):
            errors.append(f"í•„ìˆ˜ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {os.path.dirname(dir_path)}")
    
    if errors:
        raise ValueError("í™˜ê²½ ì„¤ì • ì˜¤ë¥˜:\n" + "\n".join(f"  â€¢ {error}" for error in errors))

# ì„¤ì • ìš”ì•½ ì¶œë ¥
def print_current_settings():
    """í˜„ì¬ ì„¤ì •ê°’ë“¤ì„ ì¶œë ¥í•©ë‹ˆë‹¤."""
    print("âš™ï¸  í˜„ì¬ ì„¤ì •:")
    print(f"   LLM Provider: {LLM_PROVIDER}")
    print(f"   LLM Model: {LLM_MODEL_NAME}")
    print(f"   Input Data Dir: {INPUT_DATA_DEFAULT_DIR}")
    print(f"   Output Dir: {OUTPUT_RESULTS_DIR}")
    print(f"   Log Level: {LOG_LEVEL}")

def get_api_status():
    """API í‚¤ë“¤ì˜ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤"""
    status = {}
    
    # OpenAI ìƒíƒœ í™•ì¸
    openai_key = os.getenv("OPENAI_API_KEY")
    status["openai"] = {
        "available": bool(openai_key),
        "key_preview": f"{openai_key[:10]}..." if openai_key else "ì—†ìŒ"
    }
    
    return status 