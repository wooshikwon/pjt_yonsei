"""
ContextManager: Enhanced RAG ê¸°ë°˜ Agentì˜ ì¥ê¸° ê¸°ì–µ ë° ì‘ì—… ë©”ëª¨ë¦¬ ê´€ë¦¬

LLMê³¼ì˜ ìƒí˜¸ì‘ìš©, ì£¼ìš” ë¶„ì„ ë‹¨ê³„ì˜ ì´ë ¥, Enhanced RAG ì‹œìŠ¤í…œì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨í…ìŠ¤íŠ¸ ë° 
DB ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ê´€ë¦¬í•˜ê³ , í† í° ì œí•œì„ ê³ ë ¤í•˜ì—¬ ì´ë ¥ì„ ìš”ì•½í•˜ê±°ë‚˜ í•„í„°ë§í•˜ì—¬ 
LLMì— ì „ë‹¬í•  ì»¨í…ìŠ¤íŠ¸ë¥¼ ìµœì í™”í•©ë‹ˆë‹¤.
"""

import logging
from typing import List, Dict, Any, Optional
from datetime import datetime
import json


class ContextManager:
    """
    Enhanced RAG ê¸°ë°˜ Agentì˜ ì¥ê¸° ê¸°ì–µ ë° ì‘ì—… ë©”ëª¨ë¦¬ ê´€ë¦¬ì
    
    ëŒ€í™” ì´ë ¥, ë¶„ì„ ê³¼ì •, ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨í…ìŠ¤íŠ¸, DB ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ê´€ë¦¬í•˜ë©°, 
    LLM í† í° ì œí•œì„ ê³ ë ¤í•œ ì»¨í…ìŠ¤íŠ¸ ìµœì í™” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
    """
    
    def __init__(self, llm_client, max_history_items: int = 20, 
                 summarization_trigger_count: int = 10, 
                 context_token_limit: int = 3000):
        """
        Enhanced RAG ê¸°ë°˜ ContextManager ì´ˆê¸°í™”
        
        Args:
            llm_client: ìš”ì•½ìš© LLM í´ë¼ì´ì–¸íŠ¸
            max_history_items: ìµœëŒ€ ì €ì¥í•  ìƒí˜¸ì‘ìš© ìˆ˜
            summarization_trigger_count: ìš”ì•½ íŠ¸ë¦¬ê±° ìˆ˜
            context_token_limit: LLM ì „ë‹¬ ì»¨í…ìŠ¤íŠ¸ í† í° ì œí•œ
        """
        self.llm_client = llm_client
        self.max_history_items = max_history_items
        self.summarization_trigger_count = summarization_trigger_count
        self.context_token_limit = context_token_limit
        
        # ìƒí˜¸ì‘ìš© ì´ë ¥ ì €ì¥
        self._interaction_history: List[Dict] = []
        
        # Enhanced RAG ì»¨í…ìŠ¤íŠ¸ ì €ì¥
        self._business_context: Dict = {}
        self._schema_context: Dict = {}
        self._rag_search_history: List[Dict] = []
        
        # ë¶„ì„ ìƒíƒœ ì»¨í…ìŠ¤íŠ¸
        self._analysis_context: Dict = {
            'natural_language_request': '',
            'selected_method': '',
            'data_summary': {},
            'ai_recommendations': []
        }
        
        # ìš”ì•½ ìºì‹œ
        self._summary_cache: str = ""
        self._last_summarized_index: int = 0
        
        # ë¡œê¹… ì„¤ì •
        self.logger = logging.getLogger(__name__)
    
    def add_interaction(self, role: str, content: str, node_id: str, 
                       metadata: Optional[Dict] = None):
        """
        ìƒˆë¡œìš´ ìƒí˜¸ì‘ìš©ì„ ì´ë ¥ì— ì¶”ê°€í•©ë‹ˆë‹¤.
        
        Args:
            role: ì—­í•  ('user', 'assistant', 'system', 'rag')
            content: ìƒí˜¸ì‘ìš© ë‚´ìš©
            node_id: í˜„ì¬ ì›Œí¬í”Œë¡œìš° ë…¸ë“œ ID
            metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„° (RAG ê²€ìƒ‰ ê²°ê³¼ ë“±)
        """
        interaction = {
            'role': role,
            'content': content,
            'node_id': node_id,
            'timestamp': datetime.now().isoformat(),
            'metadata': metadata or {}
        }
        
        self._interaction_history.append(interaction)
        self.logger.debug(f"ìƒí˜¸ì‘ìš© ì¶”ê°€: {role} at {node_id}")
        
        # ìš”ì•½ íŠ¸ë¦¬ê±° í™•ì¸
        if (len(self._interaction_history) - self._last_summarized_index 
            >= self.summarization_trigger_count):
            self._trigger_summarization()
        
        # ì´ë ¥ ì •ë¦¬
        if len(self._interaction_history) > self.max_history_items:
            self._prune_history()
    
    def add_business_context(self, context_data: Dict):
        """
        ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
        
        Args:
            context_data: ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨í…ìŠ¤íŠ¸ ë°ì´í„°
        """
        self._business_context.update(context_data)
        self.logger.debug("ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ë¨")
        
        # RAG ê²€ìƒ‰ ì´ë ¥ì— ì¶”ê°€
        self._rag_search_history.append({
            'type': 'business_context',
            'timestamp': datetime.now().isoformat(),
            'data': context_data
        })
    
    def add_schema_context(self, schema_data: Dict):
        """
        DB ìŠ¤í‚¤ë§ˆ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
        
        Args:
            schema_data: DB ìŠ¤í‚¤ë§ˆ ì»¨í…ìŠ¤íŠ¸ ë°ì´í„°
        """
        self._schema_context.update(schema_data)
        self.logger.debug("ìŠ¤í‚¤ë§ˆ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ë¨")
        
        # RAG ê²€ìƒ‰ ì´ë ¥ì— ì¶”ê°€
        self._rag_search_history.append({
            'type': 'schema_context',
            'timestamp': datetime.now().isoformat(),
            'data': schema_data
        })
    
    def update_analysis_context(self, key: str, value: Any):
        """
        ë¶„ì„ ìƒíƒœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        
        Args:
            key: ì»¨í…ìŠ¤íŠ¸ í‚¤
            value: ì—…ë°ì´íŠ¸í•  ê°’
        """
        self._analysis_context[key] = value
        self.logger.debug(f"ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸: {key}")
    
    def get_optimized_context(self, current_task_prompt: str, 
                            required_recent_interactions: int = 5,
                            include_rag_context: bool = True) -> str:
        """
        LLMì— ì „ë‹¬í•  ìµœì í™”ëœ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Args:
            current_task_prompt: í˜„ì¬ ì‘ì—… í”„ë¡¬í”„íŠ¸
            required_recent_interactions: í¬í•¨í•  ìµœê·¼ ìƒí˜¸ì‘ìš© ìˆ˜
            include_rag_context: RAG ì»¨í…ìŠ¤íŠ¸ í¬í•¨ ì—¬ë¶€
            
        Returns:
            str: ìµœì í™”ëœ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´
        """
        context_parts = []
        
        # 1. Enhanced RAG ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        if include_rag_context:
            rag_context = self._build_rag_context()
            if rag_context:
                context_parts.append("=== Enhanced RAG ì»¨í…ìŠ¤íŠ¸ ===")
                context_parts.append(rag_context)
                context_parts.append("")
        
        # 2. ìš”ì•½ëœ ì´ì „ ì´ë ¥ ì¶”ê°€
        if self._summary_cache:
            context_parts.append("=== ì´ì „ ë¶„ì„ ê³¼ì • ìš”ì•½ ===")
            context_parts.append(self._summary_cache)
            context_parts.append("")
        
        # 3. ìµœê·¼ ìƒí˜¸ì‘ìš© ì¶”ê°€
        recent_interactions = self._get_recent_interactions(required_recent_interactions)
        if recent_interactions:
            context_parts.append("=== ìµœê·¼ ìƒí˜¸ì‘ìš© ===")
            for interaction in recent_interactions:
                formatted_interaction = self._format_interaction(interaction)
                context_parts.append(formatted_interaction)
            context_parts.append("")
        
        # 4. í˜„ì¬ ë¶„ì„ ìƒíƒœ ì¶”ê°€
        analysis_state = self._build_analysis_state_summary()
        if analysis_state:
            context_parts.append("=== í˜„ì¬ ë¶„ì„ ìƒíƒœ ===")
            context_parts.append(analysis_state)
            context_parts.append("")
        
        # 5. í˜„ì¬ ì‘ì—… ì¶”ê°€
        context_parts.append("=== í˜„ì¬ ì‘ì—… ===")
        context_parts.append(current_task_prompt)
        
        # ì „ì²´ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        full_context = "\n".join(context_parts)
        
        # í† í° ì œí•œ í™•ì¸ ë° ì¡°ì •
        optimized_context = self._optimize_for_token_limit(full_context)
        
        return optimized_context
    
    def get_rag_context_summary(self) -> Dict[str, Any]:
        """
        Enhanced RAG ì»¨í…ìŠ¤íŠ¸ ìš”ì•½ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Returns:
            Dict: RAG ì»¨í…ìŠ¤íŠ¸ ìš”ì•½ ì •ë³´
        """
        return {
            'business_context_keys': list(self._business_context.keys()),
            'schema_context_keys': list(self._schema_context.keys()),
            'rag_searches_count': len(self._rag_search_history),
            'last_business_update': self._get_last_context_update('business_context'),
            'last_schema_update': self._get_last_context_update('schema_context')
        }
    
    def get_analysis_summary(self) -> Dict[str, Any]:
        """
        í˜„ì¬ê¹Œì§€ì˜ ë¶„ì„ ê³¼ì • ìš”ì•½ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Returns:
            Dict: ë¶„ì„ ê³¼ì • ìš”ì•½ ì •ë³´
        """
        total_interactions = len(self._interaction_history)
        
        # ì—­í• ë³„ ìƒí˜¸ì‘ìš© ìˆ˜ ê³„ì‚°
        role_counts = {}
        node_visits = {}
        
        for interaction in self._interaction_history:
            role = interaction['role']
            node_id = interaction['node_id']
            
            role_counts[role] = role_counts.get(role, 0) + 1
            node_visits[node_id] = node_visits.get(node_id, 0) + 1
        
        # ë¶„ì„ ì§„í–‰ ë‹¨ê³„ íŒŒì•…
        visited_nodes = list(node_visits.keys())
        
        return {
            'total_interactions': total_interactions,
            'role_distribution': role_counts,
            'visited_nodes': visited_nodes,
            'current_summary': self._summary_cache,
            'analysis_context': self._analysis_context,
            'rag_context_summary': self.get_rag_context_summary(),
            'analysis_start_time': (self._interaction_history[0]['timestamp'] 
                                  if self._interaction_history else None),
            'last_interaction_time': (self._interaction_history[-1]['timestamp'] 
                                    if self._interaction_history else None)
        }
    
    def _build_rag_context(self) -> str:
        """Enhanced RAG ì»¨í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤."""
        rag_parts = []
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨í…ìŠ¤íŠ¸
        if self._business_context:
            rag_parts.append("ğŸ¢ ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨í…ìŠ¤íŠ¸:")
            for key, value in self._business_context.items():
                if isinstance(value, dict) and 'summary' in value:
                    rag_parts.append(f"  â€¢ {key}: {value['summary']}")
                elif isinstance(value, str) and len(value) < 200:
                    rag_parts.append(f"  â€¢ {key}: {value}")
        
        # DB ìŠ¤í‚¤ë§ˆ ì»¨í…ìŠ¤íŠ¸
        if self._schema_context:
            if rag_parts:
                rag_parts.append("")
            rag_parts.append("ğŸ—„ï¸ DB ìŠ¤í‚¤ë§ˆ ì»¨í…ìŠ¤íŠ¸:")
            for key, value in self._schema_context.items():
                if isinstance(value, dict) and 'summary' in value:
                    rag_parts.append(f"  â€¢ {key}: {value['summary']}")
                elif isinstance(value, str) and len(value) < 200:
                    rag_parts.append(f"  â€¢ {key}: {value}")
        
        return "\n".join(rag_parts)
    
    def _build_analysis_state_summary(self) -> str:
        """í˜„ì¬ ë¶„ì„ ìƒíƒœ ìš”ì•½ì„ êµ¬ì¶•í•©ë‹ˆë‹¤."""
        state_parts = []
        
        if self._analysis_context['natural_language_request']:
            state_parts.append(f"ğŸ“ ì‚¬ìš©ì ìš”ì²­: {self._analysis_context['natural_language_request']}")
        
        if self._analysis_context['selected_method']:
            state_parts.append(f"ğŸ”¬ ì„ íƒëœ ë°©ë²•: {self._analysis_context['selected_method']}")
        
        if self._analysis_context['ai_recommendations']:
            rec_count = len(self._analysis_context['ai_recommendations'])
            state_parts.append(f"ğŸ¤– AI ì¶”ì²œ: {rec_count}ê°œ ë°©ë²• ì œì‹œë¨")
        
        return "\n".join(state_parts)
    
    def _get_last_context_update(self, context_type: str) -> Optional[str]:
        """íŠ¹ì • ì»¨í…ìŠ¤íŠ¸ ìœ í˜•ì˜ ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ì‹œê°„ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        for search in reversed(self._rag_search_history):
            if search['type'] == context_type:
                return search['timestamp']
        return None
    
    def _get_recent_interactions(self, count: int) -> List[Dict]:
        """ìµœê·¼ ìƒí˜¸ì‘ìš©ë“¤ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if count <= 0:
            return []
        
        return self._interaction_history[-count:] if self._interaction_history else []
    
    def _format_interaction(self, interaction: Dict) -> str:
        """ë‹¨ì¼ ìƒí˜¸ì‘ìš©ì„ í˜•ì‹í™”ëœ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        role = interaction['role']
        content = interaction['content']
        node_id = interaction['node_id']
        timestamp = interaction['timestamp']
        
        # ì—­í• ë³„ ì•„ì´ì½˜
        role_icons = {
            'user': 'ğŸ‘¤',
            'assistant': 'ğŸ¤–',
            'system': 'âš™ï¸'
        }
        
        icon = role_icons.get(role, 'â€¢')
        
        # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ì¶•ì•½
        if len(content) > 200:
            content = content[:197] + "..."
        
        return f"{icon} [{node_id}] {role}: {content}"
    
    def _trigger_summarization(self):
        """ì´ë ¥ ìš”ì•½ì„ íŠ¸ë¦¬ê±°í•©ë‹ˆë‹¤."""
        if len(self._interaction_history) <= self._last_summarized_index:
            return
        
        # ìš”ì•½í•  ìƒí˜¸ì‘ìš©ë“¤ ì„ íƒ
        interactions_to_summarize = self._interaction_history[
            self._last_summarized_index:
            self._last_summarized_index + self.summarization_trigger_count
        ]
        
        if not interactions_to_summarize:
            return
        
        try:
            # ìƒˆë¡œìš´ ìš”ì•½ ìƒì„±
            new_summary = self._summarize_interactions(interactions_to_summarize)
            
            # ê¸°ì¡´ ìš”ì•½ê³¼ ê²°í•©
            if self._summary_cache:
                combined_summary = f"{self._summary_cache}\n\n{new_summary}"
                # ê²°í•©ëœ ìš”ì•½ì´ ë„ˆë¬´ ê¸¸ë©´ ë‹¤ì‹œ ìš”ì•½
                if len(combined_summary) > 1000:
                    self._summary_cache = self._summarize_text(combined_summary)
                else:
                    self._summary_cache = combined_summary
            else:
                self._summary_cache = new_summary
            
            # ìš”ì•½ëœ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
            self._last_summarized_index += len(interactions_to_summarize)
            
            self.logger.info(f"ì´ë ¥ ìš”ì•½ ì™„ë£Œ: {len(interactions_to_summarize)}ê°œ ìƒí˜¸ì‘ìš©")
            
        except Exception as e:
            self.logger.error(f"ì´ë ¥ ìš”ì•½ ì‹¤íŒ¨: {e}")
    
    def _summarize_interactions(self, interactions: List[Dict]) -> str:
        """ì£¼ì–´ì§„ ìƒí˜¸ì‘ìš©ë“¤ì„ ìš”ì•½í•©ë‹ˆë‹¤."""
        # ìƒí˜¸ì‘ìš©ë“¤ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        interaction_texts = []
        for interaction in interactions:
            formatted = self._format_interaction(interaction)
            interaction_texts.append(formatted)
        
        interactions_text = "\n".join(interaction_texts)
        
        # ìš”ì•½ í”„ë¡¬í”„íŠ¸ ìƒì„±
        summary_prompt = f"""
ë‹¤ìŒì€ í†µê³„ ë¶„ì„ ì›Œí¬í”Œë¡œìš°ì˜ ìƒí˜¸ì‘ìš© ê¸°ë¡ì…ë‹ˆë‹¤. 
ì£¼ìš” ë‚´ìš©ê³¼ ê²°ì •ì‚¬í•­ì„ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:

{interactions_text}

ìš”ì•½:
"""
        
        try:
            # LLMì„ ì‚¬ìš©í•œ ìš”ì•½
            summary = self.llm_client.generate_text(
                prompt=summary_prompt,
                temperature=0.3
            )
            return summary.strip()
            
        except Exception as e:
            self.logger.error(f"LLM ìš”ì•½ ì‹¤íŒ¨: {e}")
            # í´ë°±: ë‹¨ìˆœ ìš”ì•½
            return self._simple_summarize(interactions)
    
    def _summarize_text(self, text: str) -> str:
        """ê¸´ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤."""
        summary_prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ í•µì‹¬ ë‚´ìš©ë§Œ í¬í•¨í•˜ì—¬ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:

{text}

ìš”ì•½:
"""
        
        try:
            summary = self.llm_client.generate_text(
                prompt=summary_prompt,
                temperature=0.3
            )
            return summary.strip()
        except Exception as e:
            self.logger.error(f"í…ìŠ¤íŠ¸ ìš”ì•½ ì‹¤íŒ¨: {e}")
            # í´ë°±: ë‹¨ìˆœ ì¶•ì•½
            return text[:500] + "..." if len(text) > 500 else text
    
    def _simple_summarize(self, interactions: List[Dict]) -> str:
        """ê°„ë‹¨í•œ ìš”ì•½ (LLM ì‹¤íŒ¨ì‹œ í´ë°±)"""
        if not interactions:
            return ""
        
        # ë…¸ë“œë³„ ê·¸ë£¹í™”
        nodes = set(interaction['node_id'] for interaction in interactions)
        
        summary_parts = []
        summary_parts.append(f"ì²˜ë¦¬ëœ ë…¸ë“œ: {', '.join(sorted(nodes))}")
        summary_parts.append(f"ì´ ìƒí˜¸ì‘ìš©: {len(interactions)}ê°œ")
        
        # ì£¼ìš” ê²°ì •ì‚¬í•­ ì¶”ì¶œ
        decisions = []
        for interaction in interactions:
            if interaction['role'] == 'user' and len(interaction['content']) < 50:
                decisions.append(interaction['content'])
        
        if decisions:
            summary_parts.append(f"ì£¼ìš” ê²°ì •: {', '.join(decisions[:3])}")
        
        return " | ".join(summary_parts)
    
    def _optimize_for_token_limit(self, context: str) -> str:
        """í† í° ì œí•œì— ë§ê²Œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìµœì í™”í•©ë‹ˆë‹¤."""
        # ê°„ë‹¨í•œ í† í° ì¶”ì • (ì‹¤ì œë¡œëŠ” tokenizer ì‚¬ìš© ê¶Œì¥)
        estimated_tokens = len(context.split()) * 1.3
        
        if estimated_tokens <= self.context_token_limit:
            return context
        
        # í† í° ì œí•œ ì´ˆê³¼ì‹œ ì¶•ì•½
        self.logger.warning(f"ì»¨í…ìŠ¤íŠ¸ í† í° ì œí•œ ì´ˆê³¼: {estimated_tokens:.0f} > {self.context_token_limit}")
        
        # ìµœê·¼ ìƒí˜¸ì‘ìš© ìˆ˜ë¥¼ ì¤„ì—¬ì„œ ì¬ìƒì„±
        lines = context.split('\n')
        
        # í˜„ì¬ ì‘ì—… ë¶€ë¶„ì€ ìœ ì§€
        current_task_index = -1
        for i, line in enumerate(lines):
            if "=== í˜„ì¬ ì‘ì—… ===" in line:
                current_task_index = i
                break
        
        if current_task_index > 0:
            # í˜„ì¬ ì‘ì—… ì´ì „ ë¶€ë¶„ì„ ì¶•ì•½
            before_current = lines[:current_task_index]
            current_and_after = lines[current_task_index:]
            
            # ì´ì „ ë¶€ë¶„ì„ ì ˆë°˜ìœ¼ë¡œ ì¶•ì•½
            truncated_before = before_current[:len(before_current)//2]
            truncated_before.append("... (ì¤‘ê°„ ë‚´ìš© ìƒëµ) ...")
            
            optimized_lines = truncated_before + current_and_after
            return '\n'.join(optimized_lines)
        
        # í´ë°±: ì „ì²´ë¥¼ ì ˆë°˜ìœ¼ë¡œ ì¶•ì•½
        return '\n'.join(lines[:len(lines)//2]) + "\n... (ë‚´ìš© ìƒëµ) ..."
    
    def _prune_history(self):
        """ì˜¤ë˜ëœ ìƒí˜¸ì‘ìš© ê¸°ë¡ì„ ì •ë¦¬í•©ë‹ˆë‹¤."""
        if len(self._interaction_history) <= self.max_history_items:
            return
        
        # ê°€ì¥ ì˜¤ë˜ëœ ìƒí˜¸ì‘ìš©ë“¤ ì œê±° (ìš”ì•½ëœ ë¶€ë¶„ ì œì™¸)
        items_to_remove = len(self._interaction_history) - self.max_history_items
        
        # ìš”ì•½ë˜ì§€ ì•Šì€ ë¶€ë¶„ë¶€í„° ì œê±°
        removal_start = max(0, self._last_summarized_index)
        removal_end = min(removal_start + items_to_remove, len(self._interaction_history))
        
        if removal_end > removal_start:
            removed_items = self._interaction_history[removal_start:removal_end]
            self._interaction_history = (
                self._interaction_history[:removal_start] + 
                self._interaction_history[removal_end:]
            )
            
            # ì¸ë±ìŠ¤ ì¡°ì •
            self._last_summarized_index = max(0, self._last_summarized_index - len(removed_items))
            
            self.logger.info(f"ì´ë ¥ ì •ë¦¬ ì™„ë£Œ: {len(removed_items)}ê°œ ìƒí˜¸ì‘ìš© ì œê±°")
    
    def reset_context(self):
        """ì»¨í…ìŠ¤íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self._interaction_history.clear()
        self._summary_cache = ""
        self._last_summarized_index = 0
        self.logger.info("ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ") 