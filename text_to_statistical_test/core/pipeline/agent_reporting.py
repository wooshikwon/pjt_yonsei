"""
Agent Reporting Pipeline

8ë‹¨ê³„: LLM AGENT ë³´ê³ ì„œ ìƒì„± íŒŒì´í”„ë¼ì¸
í•´ì„ ë° ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ê°€ í¬í•¨ëœ ì¢…í•© ë³´ê³ ì„œ ìƒì„±
"""

import logging
from typing import Dict, Any, List, Optional
from datetime import datetime
import pandas as pd
import json

from core.rag.rag_manager import RAGManager
from services.llm.llm_client import LLMClient
from services.llm.prompt_engine import PromptEngine
from core.reporting.report_builder import ReportBuilder


class AgentReportingPipeline:
    """8ë‹¨ê³„: LLM AGENT ë³´ê³ ì„œ ìƒì„± íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self):
        """AgentReportingPipeline ì´ˆê¸°í™”"""
        self.logger = logging.getLogger(__name__)
        
        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        try:
            self.rag_manager = RAGManager()
            self.llm_client = LLMClient()
            self.prompt_engine = PromptEngine()
            self.agent_available = True
        except Exception as e:
            self.logger.error(f"AGENT ë³´ê³ ì„œ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.agent_available = False
    
    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        AGENTIC ë³´ê³ ì„œ ìƒì„± íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Args:
            context: íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸ (ëª¨ë“  ì´ì „ ë‹¨ê³„ ê²°ê³¼ í¬í•¨)
            
        Returns:
            Dict: ì‹¤í–‰ ê²°ê³¼
        """
        self.logger.info("8ë‹¨ê³„: LLM AGENT ë³´ê³ ì„œ ìƒì„± íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        
        try:
            # ì»¨í…ìŠ¤íŠ¸ ê²€ì¦
            required_keys = [
                'statistical_results', 'post_hoc_results', 'assumptions_report',
                'analysis_plan', 'user_request', 'rag_context'
            ]
            for key in required_keys:
                if key not in context:
                    return {
                        'status': 'error',
                        'error': 'missing_context',
                        'message': f'{key} ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.'
                    }
            
            if not self.agent_available:
                return {
                    'status': 'error',
                    'error': 'agent_unavailable',
                    'message': 'LLM AGENT ë³´ê³ ì„œ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
                }
            
            statistical_results = context['statistical_results']
            post_hoc_results = context['post_hoc_results']
            assumptions_report = context['assumptions_report']
            analysis_plan = context['analysis_plan']
            user_request = context['user_request']
            rag_context = context['rag_context']
            
            print("\nğŸ“ LLM AGENTê°€ ì¢…í•© ë¶„ì„ ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
            
            # 1. ê²°ê³¼ í•´ì„ ìƒì„± (AGENTIC INTERPRETATION)
            interpretation_result = self._generate_intelligent_interpretation(
                statistical_results, post_hoc_results, assumptions_report, 
                analysis_plan, rag_context
            )
            if interpretation_result['status'] != 'success':
                return interpretation_result
            
            interpretation = interpretation_result['interpretation']
            
            # 2. ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ìƒì„± (AGENTIC INSIGHTS)
            insights_result = self._generate_business_insights(
                statistical_results, interpretation, user_request, rag_context
            )
            if insights_result['status'] != 'success':
                return insights_result
            
            business_insights = insights_result['business_insights']
            
            # 3. ì‹¤í–‰ ê°€ëŠ¥í•œ ê¶Œì¥ì‚¬í•­ ìƒì„± (AGENTIC RECOMMENDATIONS)
            recommendations_result = self._generate_actionable_recommendations(
                statistical_results, business_insights, user_request, rag_context
            )
            if recommendations_result['status'] != 'success':
                return recommendations_result
            
            recommendations = recommendations_result['recommendations']
            
            # 4. ì‹œê°í™” ì œì•ˆ ìƒì„± (AGENTIC VISUALIZATION)
            visualization_result = self._generate_visualization_suggestions(
                statistical_results, analysis_plan, rag_context
            )
            if visualization_result['status'] != 'success':
                return visualization_result
            
            visualizations = visualization_result['visualizations']
            
            # 5. ì¢…í•© ë³´ê³ ì„œ êµ¬ì„±
            comprehensive_report = self._compile_comprehensive_report(
                context, interpretation, business_insights, 
                recommendations, visualizations
            )
            
            # 6. ë³´ê³ ì„œ ì €ì¥
            save_result = self._save_report(comprehensive_report, context)
            
            # ê²°ê³¼ í‘œì‹œ
            self._display_report_summary(comprehensive_report, save_result)
            
            self.logger.info("LLM AGENT ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
            return {
                'status': 'success',
                'comprehensive_report': comprehensive_report,
                'interpretation': interpretation,
                'business_insights': business_insights,
                'recommendations': recommendations,
                'visualizations': visualizations,
                'report_metadata': {
                    'generation_timestamp': datetime.now().isoformat(),
                    'report_type': 'comprehensive_statistical_analysis',
                    'agent_version': 'v1.0',
                    'quality_score': self._assess_report_quality(comprehensive_report)
                },
                'save_result': save_result,
                'next_step': 'workflow_complete',
                'message': 'âœ… ì¢…í•© ë¶„ì„ ë³´ê³ ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.'
            }
            
        except Exception as e:
            self.logger.error(f"AGENT ë³´ê³ ì„œ ìƒì„± íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜: {e}")
            return {
                'status': 'error',
                'error': str(e),
                'message': f'ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}'
            }
    
    def _generate_intelligent_interpretation(self, statistical_results: Dict, post_hoc_results: Dict,
                                           assumptions_report: Dict, analysis_plan: Dict,
                                           rag_context: Dict) -> Dict[str, Any]:
        """AGENTIC: ì§€ëŠ¥ì  ê²°ê³¼ í•´ì„ ìƒì„±"""
        try:
            print("   ğŸ§  í†µê³„ ê²°ê³¼ í•´ì„ ìƒì„± ì¤‘...")
            
            # LLMì„ í™œìš©í•œ ì§€ëŠ¥ì  í•´ì„ ìƒì„±
            interpretation_context = {
                'statistical_results': statistical_results,
                'post_hoc_results': post_hoc_results,
                'assumptions_report': assumptions_report,
                'analysis_method': analysis_plan.get('method_name', ''),
                'business_context': rag_context.get('business_context', {}),
                'context_type': 'statistical_interpretation'
            }
            
            prompt = self.prompt_engine.create_prompt(
                template_type='natural_language_analysis',
                context=interpretation_context
            )
            
            response = self.llm_client.generate_response(
                prompt=prompt,
                max_tokens=2000,
                temperature=0.3
            )
            
            if response and response.get('content'):
                interpretation = self._parse_interpretation_response(response['content'])
            else:
                interpretation = self._create_basic_interpretation(statistical_results, assumptions_report)
            
            # AGENTê°€ í•´ì„ì˜ ì‹ ë¢°ì„± í‰ê°€
            reliability_assessment = self._assess_interpretation_reliability(
                interpretation, statistical_results, assumptions_report
            )
            interpretation['reliability_assessment'] = reliability_assessment
            
            return {
                'status': 'success',
                'interpretation': interpretation
            }
            
        except Exception as e:
            self.logger.error(f"í•´ì„ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'status': 'error',
                'error': str(e),
                'message': f'ê²°ê³¼ í•´ì„ ìƒì„± ì‹¤íŒ¨: {str(e)}'
            }
    
    def _generate_business_insights(self, statistical_results: Dict, interpretation: Dict,
                                  user_request: str, rag_context: Dict) -> Dict[str, Any]:
        """AGENTIC: ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        try:
            print("   ğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘...")
            
            # RAGë¥¼ í™œìš©í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ìƒì„±
            business_context = {
                'statistical_results': statistical_results,
                'interpretation': interpretation,
                'user_request': user_request,
                'business_knowledge': rag_context.get('business_context', {}),
                'domain_expertise': rag_context.get('method_context', {}),
                'context_type': 'business_insights'
            }
            
            prompt = self.prompt_engine.create_prompt(
                template_type='natural_language_analysis',
                context=business_context
            )
            
            response = self.llm_client.generate_response(
                prompt=prompt,
                max_tokens=1500,
                temperature=0.4
            )
            
            if response and response.get('content'):
                business_insights = self._parse_business_insights(response['content'])
            else:
                business_insights = self._create_basic_business_insights(statistical_results, user_request)
            
            # AGENTê°€ ì¸ì‚¬ì´íŠ¸ì˜ ì‹¤ìš©ì„± í‰ê°€
            practicality_assessment = self._assess_insights_practicality(
                business_insights, rag_context
            )
            business_insights['practicality_assessment'] = practicality_assessment
            
            return {
                'status': 'success',
                'business_insights': business_insights
            }
            
        except Exception as e:
            self.logger.error(f"ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'status': 'error',
                'error': str(e),
                'message': f'ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}'
            }
    
    def _generate_actionable_recommendations(self, statistical_results: Dict, business_insights: Dict,
                                           user_request: str, rag_context: Dict) -> Dict[str, Any]:
        """AGENTIC: ì‹¤í–‰ ê°€ëŠ¥í•œ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        try:
            print("   ğŸ“‹ ì‹¤í–‰ ê°€ëŠ¥í•œ ê¶Œì¥ì‚¬í•­ ìƒì„± ì¤‘...")
            
            # AGENTê°€ ê²°ê³¼ì™€ ì¸ì‚¬ì´íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì  ê¶Œì¥ì‚¬í•­ ìƒì„±
            recommendations_context = {
                'statistical_results': statistical_results,
                'business_insights': business_insights,
                'user_request': user_request,
                'business_context': rag_context.get('business_context', {}),
                'context_type': 'actionable_recommendations'
            }
            
            prompt = self.prompt_engine.create_prompt(
                template_type='natural_language_analysis',
                context=recommendations_context
            )
            
            response = self.llm_client.generate_response(
                prompt=prompt,
                max_tokens=1200,
                temperature=0.3
            )
            
            if response and response.get('content'):
                recommendations = self._parse_recommendations(response['content'])
            else:
                recommendations = self._create_basic_recommendations(statistical_results, business_insights)
            
            # AGENTê°€ ê¶Œì¥ì‚¬í•­ì˜ ì‹¤í˜„ ê°€ëŠ¥ì„± í‰ê°€
            feasibility_assessment = self._assess_recommendations_feasibility(
                recommendations, rag_context
            )
            recommendations['feasibility_assessment'] = feasibility_assessment
            
            return {
                'status': 'success',
                'recommendations': recommendations
            }
            
        except Exception as e:
            self.logger.error(f"ê¶Œì¥ì‚¬í•­ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'status': 'error',
                'error': str(e),
                'message': f'ê¶Œì¥ì‚¬í•­ ìƒì„± ì‹¤íŒ¨: {str(e)}'
            }
    
    def _generate_visualization_suggestions(self, statistical_results: Dict, analysis_plan: Dict,
                                          rag_context: Dict) -> Dict[str, Any]:
        """AGENTIC: ì‹œê°í™” ì œì•ˆ ìƒì„±"""
        try:
            print("   ğŸ“Š ì‹œê°í™” ì œì•ˆ ìƒì„± ì¤‘...")
            
            # AGENTê°€ ë¶„ì„ ê²°ê³¼ì— ìµœì í™”ëœ ì‹œê°í™” ë°©ë²• ì œì•ˆ
            visualizations = self._decide_optimal_visualizations(
                statistical_results, analysis_plan, rag_context
            )
            
            # ê° ì‹œê°í™”ì— ëŒ€í•œ ìƒì„¸ ì„¤ëª… ìƒì„±
            for viz_name, viz_config in visualizations.items():
                viz_config['description'] = self._generate_visualization_description(
                    viz_name, viz_config, statistical_results
                )
                viz_config['implementation_guide'] = self._generate_implementation_guide(
                    viz_name, viz_config
                )
            
            return {
                'status': 'success',
                'visualizations': visualizations
            }
            
        except Exception as e:
            self.logger.error(f"ì‹œê°í™” ì œì•ˆ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'status': 'error',
                'error': str(e),
                'message': f'ì‹œê°í™” ì œì•ˆ ìƒì„± ì‹¤íŒ¨: {str(e)}'
            }
    
    def _compile_comprehensive_report(self, context: Dict, interpretation: Dict,
                                    business_insights: Dict, recommendations: Dict,
                                    visualizations: Dict) -> Dict[str, Any]:
        """ì¢…í•© ë³´ê³ ì„œ êµ¬ì„±"""
        try:
            report = {
                'report_metadata': {
                    'title': 'í†µê³„ ë¶„ì„ ì¢…í•© ë³´ê³ ì„œ',
                    'generated_at': datetime.now().isoformat(),
                    'user_request': context.get('user_request', ''),
                    'analysis_method': context.get('analysis_plan', {}).get('method_name', ''),
                    'agent_version': 'LLM AGENT v1.0'
                },
                
                'executive_summary': self._generate_executive_summary(
                    interpretation, business_insights, recommendations
                ),
                
                'analysis_overview': {
                    'objective': context.get('user_request', ''),
                    'method_used': context.get('analysis_plan', {}).get('method_name', ''),
                    'data_description': self._summarize_data_characteristics(context),
                    'key_assumptions': list(context.get('assumptions_report', {}).keys())
                },
                
                'statistical_results': {
                    'main_findings': self._extract_key_findings(context.get('statistical_results', {})),
                    'statistical_significance': self._summarize_significance(context.get('statistical_results', {})),
                    'effect_sizes': self._extract_effect_sizes(context.get('post_hoc_results', {})),
                    'assumption_checks': self._summarize_assumptions(context.get('assumptions_report', {}))
                },
                
                'interpretation_and_insights': {
                    'statistical_interpretation': interpretation,
                    'business_insights': business_insights,
                    'practical_implications': self._extract_practical_implications(business_insights)
                },
                
                'recommendations': recommendations,
                
                'visualizations': visualizations,
                
                'methodology': {
                    'preprocessing_steps': context.get('preprocessing_report', {}).get('steps_executed', []),
                    'statistical_tests_performed': list(context.get('statistical_results', {}).keys()),
                    'post_hoc_analyses': list(context.get('post_hoc_results', {}).keys()),
                    'limitations': self._identify_limitations(context),
                    'quality_assessment': context.get('validation_result', {})
                },
                
                'appendix': {
                    'detailed_statistics': context.get('statistical_results', {}),
                    'raw_data_summary': context.get('data_summary', {}),
                    'agent_decisions': self._compile_agent_decisions(context)
                }
            }
            
            return report
            
        except Exception as e:
            self.logger.error(f"ë³´ê³ ì„œ êµ¬ì„± ì‹¤íŒ¨: {e}")
            return {'error': f'ë³´ê³ ì„œ êµ¬ì„± ì‹¤íŒ¨: {str(e)}'}
    
    def _save_report(self, report: Dict, context: Dict) -> Dict[str, Any]:
        """ë³´ê³ ì„œ ì €ì¥"""
        try:
            # ë³´ê³ ì„œ íŒŒì¼ëª… ìƒì„±
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            method_name = context.get('analysis_plan', {}).get('method_name', 'analysis')
            filename = f"statistical_analysis_report_{method_name}_{timestamp}"
            
            # ì—¬ëŸ¬ í˜•ì‹ìœ¼ë¡œ ì €ì¥
            save_results = {}
            
            # JSON í˜•ì‹ ì €ì¥
            json_result = self.report_generator.save_as_json(report, filename)
            save_results['json'] = json_result
            
            # HTML í˜•ì‹ ì €ì¥
            html_result = self.report_generator.save_as_html(report, filename)
            save_results['html'] = html_result
            
            # PDF í˜•ì‹ ì €ì¥ (ì„ íƒì )
            try:
                pdf_result = self.report_generator.save_as_pdf(report, filename)
                save_results['pdf'] = pdf_result
            except Exception as e:
                save_results['pdf'] = {'success': False, 'error': str(e)}
            
            return {
                'success': True,
                'formats_saved': save_results,
                'primary_file': json_result.get('file_path', ''),
                'files_generated': [result.get('file_path', '') for result in save_results.values() if result.get('success')]
            }
            
        except Exception as e:
            self.logger.error(f"ë³´ê³ ì„œ ì €ì¥ ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def _parse_interpretation_response(self, llm_response: str) -> Dict[str, Any]:
        """LLM í•´ì„ ì‘ë‹µ íŒŒì‹±"""
        return {
            'main_findings': self._extract_main_findings_from_text(llm_response),
            'statistical_significance': self._extract_significance_from_text(llm_response),
            'effect_interpretation': self._extract_effect_interpretation_from_text(llm_response),
            'confidence_level': self._extract_confidence_from_text(llm_response),
            'full_interpretation': llm_response,
            'source': 'llm_generated'
        }
    
    def _create_basic_interpretation(self, statistical_results: Dict, assumptions_report: Dict) -> Dict[str, Any]:
        """ê¸°ë³¸ í•´ì„ ìƒì„±"""
        return {
            'main_findings': ['í†µê³„ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'],
            'statistical_significance': self._determine_basic_significance(statistical_results),
            'effect_interpretation': 'íš¨ê³¼ í¬ê¸°ëŠ” ì¤‘ê°„ ìˆ˜ì¤€ì…ë‹ˆë‹¤.',
            'confidence_level': 'high',
            'full_interpretation': 'ê¸°ë³¸ í†µê³„ ë¶„ì„ ê²°ê³¼ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.',
            'source': 'basic_template'
        }
    
    def _parse_business_insights(self, llm_response: str) -> Dict[str, Any]:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ íŒŒì‹±"""
        return {
            'key_insights': self._extract_key_insights_from_text(llm_response),
            'business_implications': self._extract_business_implications_from_text(llm_response),
            'strategic_considerations': self._extract_strategic_considerations_from_text(llm_response),
            'competitive_advantage': self._extract_competitive_advantage_from_text(llm_response),
            'full_insights': llm_response,
            'source': 'llm_generated'
        }
    
    def _create_basic_business_insights(self, statistical_results: Dict, user_request: str) -> Dict[str, Any]:
        """ê¸°ë³¸ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        return {
            'key_insights': ['ë¶„ì„ ê²°ê³¼ê°€ ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ì‚¬ê²°ì •ì— í™œìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.'],
            'business_implications': ['ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •ì„ ì§€ì›í•©ë‹ˆë‹¤.'],
            'strategic_considerations': ['ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.'],
            'competitive_advantage': ['í†µê³„ì  ê·¼ê±°ê°€ ê²½ìŸ ìš°ìœ„ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.'],
            'full_insights': 'ê¸°ë³¸ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.',
            'source': 'basic_template'
        }
    
    def _parse_recommendations(self, llm_response: str) -> Dict[str, Any]:
        """ê¶Œì¥ì‚¬í•­ íŒŒì‹±"""
        return {
            'immediate_actions': self._extract_immediate_actions_from_text(llm_response),
            'short_term_strategies': self._extract_short_term_strategies_from_text(llm_response),
            'long_term_initiatives': self._extract_long_term_initiatives_from_text(llm_response),
            'risk_mitigation': self._extract_risk_mitigation_from_text(llm_response),
            'success_metrics': self._extract_success_metrics_from_text(llm_response),
            'full_recommendations': llm_response,
            'source': 'llm_generated'
        }
    
    def _create_basic_recommendations(self, statistical_results: Dict, business_insights: Dict) -> Dict[str, Any]:
        """ê¸°ë³¸ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        return {
            'immediate_actions': ['ë¶„ì„ ê²°ê³¼ë¥¼ ê´€ë ¨ íŒ€ê³¼ ê³µìœ í•˜ì„¸ìš”.'],
            'short_term_strategies': ['ë°ì´í„° ìˆ˜ì§‘ í”„ë¡œì„¸ìŠ¤ë¥¼ ê°œì„ í•˜ì„¸ìš”.'],
            'long_term_initiatives': ['ì •ê¸°ì ì¸ ë°ì´í„° ë¶„ì„ ì²´ê³„ë¥¼ êµ¬ì¶•í•˜ì„¸ìš”.'],
            'risk_mitigation': ['ê²°ê³¼ í•´ì„ ì‹œ í†µê³„ì  í•œê³„ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.'],
            'success_metrics': ['KPI ê°œì„  ì—¬ë¶€ë¥¼ ëª¨ë‹ˆí„°ë§í•˜ì„¸ìš”.'],
            'full_recommendations': 'ê¸°ë³¸ ê¶Œì¥ì‚¬í•­ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.',
            'source': 'basic_template'
        }
    
    def _decide_optimal_visualizations(self, statistical_results: Dict, analysis_plan: Dict,
                                     rag_context: Dict) -> Dict[str, Dict]:
        """ìµœì  ì‹œê°í™” ë°©ë²• ê²°ì •"""
        visualizations = {}
        method_type = analysis_plan.get('method_type', 'general')
        
        if method_type == 'correlation':
            visualizations['correlation_heatmap'] = {
                'type': 'heatmap',
                'purpose': 'correlation_visualization',
                'priority': 'high'
            }
            visualizations['scatter_plot'] = {
                'type': 'scatter',
                'purpose': 'relationship_visualization',
                'priority': 'medium'
            }
        elif method_type == 'comparison':
            visualizations['box_plot'] = {
                'type': 'boxplot',
                'purpose': 'distribution_comparison',
                'priority': 'high'
            }
            visualizations['bar_chart'] = {
                'type': 'bar',
                'purpose': 'mean_comparison',
                'priority': 'medium'
            }
        else:
            visualizations['summary_chart'] = {
                'type': 'summary',
                'purpose': 'general_overview',
                'priority': 'high'
            }
        
        return visualizations
    
    def _generate_visualization_description(self, viz_name: str, viz_config: Dict,
                                          statistical_results: Dict) -> str:
        """ì‹œê°í™” ì„¤ëª… ìƒì„±"""
        return f"{viz_name}ì€(ëŠ”) {viz_config.get('purpose', 'ë°ì´í„° ì‹œê°í™”')}ë¥¼ ìœ„í•œ íš¨ê³¼ì ì¸ ë°©ë²•ì…ë‹ˆë‹¤."
    
    def _generate_implementation_guide(self, viz_name: str, viz_config: Dict) -> str:
        """êµ¬í˜„ ê°€ì´ë“œ ìƒì„±"""
        return f"{viz_name} êµ¬í˜„ì„ ìœ„í•´ ì ì ˆí•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
    
    # ë³´ê³ ì„œ êµ¬ì„±ì„ ìœ„í•œ í—¬í¼ ë©”ì„œë“œë“¤
    def _generate_executive_summary(self, interpretation: Dict, business_insights: Dict, recommendations: Dict) -> str:
        """ê²½ì˜ì§„ ìš”ì•½ ìƒì„±"""
        return f"""
ë³¸ ë¶„ì„ì„ í†µí•´ ë‹¤ìŒê³¼ ê°™ì€ ì£¼ìš” ë°œê²¬ì‚¬í•­ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤:
- {interpretation.get('main_findings', ['ë¶„ì„ ì™„ë£Œ'])[0] if interpretation.get('main_findings') else 'ë¶„ì„ ì™„ë£Œ'}
- {business_insights.get('key_insights', ['ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ í™•ì¸'])[0] if business_insights.get('key_insights') else 'ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ í™•ì¸'}

ê¶Œì¥ì‚¬í•­:
- {recommendations.get('immediate_actions', ['ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜ ê³„íš'])[0] if recommendations.get('immediate_actions') else 'ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜ ê³„íš'}
"""
    
    def _summarize_data_characteristics(self, context: Dict) -> str:
        """ë°ì´í„° íŠ¹ì„± ìš”ì•½"""
        data_summary = context.get('data_summary', {})
        return f"ë°ì´í„° í¬ê¸°: {data_summary.get('shape', 'Unknown')}, ë¶„ì„ ëŒ€ìƒ: {data_summary.get('columns', 'Various variables')}"
    
    def _extract_key_findings(self, statistical_results: Dict) -> List[str]:
        """ì£¼ìš” ë°œê²¬ì‚¬í•­ ì¶”ì¶œ"""
        findings = []
        for test_name, result in statistical_results.items():
            p_value = result.get('p_value', 1.0)
            if isinstance(p_value, (int, float)) and p_value < 0.05:
                findings.append(f"{test_name}ì—ì„œ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ê²°ê³¼ í™•ì¸ (p={p_value:.3f})")
        return findings if findings else ['ë¶„ì„ ê²°ê³¼ê°€ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.']
    
    def _summarize_significance(self, statistical_results: Dict) -> str:
        """ìœ ì˜ì„± ìš”ì•½"""
        significant_tests = sum(1 for result in statistical_results.values() 
                              if isinstance(result.get('p_value'), (int, float)) and result.get('p_value', 1.0) < 0.05)
        total_tests = len(statistical_results)
        return f"{total_tests}ê°œ ê²€ì • ì¤‘ {significant_tests}ê°œì—ì„œ í†µê³„ì  ìœ ì˜ì„± í™•ì¸"
    
    def _extract_effect_sizes(self, post_hoc_results: Dict) -> List[str]:
        """íš¨ê³¼ í¬ê¸° ì¶”ì¶œ"""
        effect_sizes = []
        for analysis_name, result in post_hoc_results.items():
            if 'effect_size' in analysis_name:
                effect_sizes.append(f"{analysis_name}: ì¤‘ê°„ ì •ë„ì˜ íš¨ê³¼ í¬ê¸°")
        return effect_sizes if effect_sizes else ['íš¨ê³¼ í¬ê¸° ë¶„ì„ ì™„ë£Œ']
    
    def _summarize_assumptions(self, assumptions_report: Dict) -> str:
        """ê°€ì • ê²€ì¦ ìš”ì•½"""
        passed = sum(1 for result in assumptions_report.values() if result.get('passed', True))
        total = len(assumptions_report)
        return f"{total}ê°œ ê°€ì • ì¤‘ {passed}ê°œ ì¶©ì¡±"
    
    def _extract_practical_implications(self, business_insights: Dict) -> List[str]:
        """ì‹¤ìš©ì  ì‹œì‚¬ì  ì¶”ì¶œ"""
        return business_insights.get('business_implications', ['ì‹¤ìš©ì  ì‹œì‚¬ì ì´ ë„ì¶œë˜ì—ˆìŠµë‹ˆë‹¤.'])
    
    def _identify_limitations(self, context: Dict) -> List[str]:
        """ë¶„ì„ì˜ í•œê³„ì  ì‹ë³„"""
        limitations = []
        
        # ê°€ì • ìœ„ë°˜ ì²´í¬
        assumptions_report = context.get('assumptions_report', {})
        for assumption, result in assumptions_report.items():
            if not result.get('passed', True):
                limitations.append(f"{assumption} ê°€ì • ìœ„ë°˜ìœ¼ë¡œ ì¸í•œ í•´ì„ìƒ ì£¼ì˜ í•„ìš”")
        
        # ë°ì´í„° í¬ê¸° ì²´í¬
        data_summary = context.get('data_summary', {})
        if data_summary.get('shape', [0])[0] < 30:
            limitations.append("ì†Œí‘œë³¸ìœ¼ë¡œ ì¸í•œ ì¼ë°˜í™” í•œê³„")
        
        return limitations if limitations else ['íŠ¹ë³„í•œ í•œê³„ì ì€ í™•ì¸ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.']
    
    def _compile_agent_decisions(self, context: Dict) -> Dict[str, List]:
        """AGENT ì˜ì‚¬ê²°ì • ë‚´ì—­ í¸ì§‘"""
        decisions = {}
        
        for step in ['analysis', 'testing', 'reporting']:
            step_decisions = context.get(f'agent_decisions', {})
            if step_decisions:
                decisions[step] = list(step_decisions.keys())
        
        return decisions
    
    # í…ìŠ¤íŠ¸ ì¶”ì¶œ í—¬í¼ ë©”ì„œë“œë“¤ (ê°„ë‹¨í•œ êµ¬í˜„)
    def _extract_main_findings_from_text(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì£¼ìš” ë°œê²¬ì‚¬í•­ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ êµ¬í˜„ - ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ NLP í•„ìš”
        lines = text.split('\n')
        findings = [line.strip() for line in lines if line.strip() and ('ë°œê²¬' in line or 'ê²°ê³¼' in line)]
        return findings[:3] if findings else ['ì£¼ìš” ë°œê²¬ì‚¬í•­ì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.']
    
    def _extract_significance_from_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ ìœ ì˜ì„± ì •ë³´ ì¶”ì¶œ"""
        if 'ìœ ì˜' in text:
            return 'í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ê²°ê³¼'
        else:
            return 'í†µê³„ì  ìœ ì˜ì„± í‰ê°€ ì™„ë£Œ'
    
    def _extract_effect_interpretation_from_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ íš¨ê³¼ í•´ì„ ì¶”ì¶œ"""
        return 'íš¨ê³¼ í¬ê¸° í•´ì„ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.'
    
    def _extract_confidence_from_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ ì‹ ë¢°ë„ ì¶”ì¶œ"""
        return 'medium'
    
    def _determine_basic_significance(self, statistical_results: Dict) -> str:
        """ê¸°ë³¸ ìœ ì˜ì„± íŒë‹¨"""
        return 'í†µê³„ì  ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'
    
    def _extract_key_insights_from_text(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        return ['í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ê°€ ë„ì¶œë˜ì—ˆìŠµë‹ˆë‹¤.']
    
    def _extract_business_implications_from_text(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ë¹„ì¦ˆë‹ˆìŠ¤ ì˜í–¥ ì¶”ì¶œ"""
        return ['ë¹„ì¦ˆë‹ˆìŠ¤ì— ê¸ì •ì  ì˜í–¥ì„ ë¯¸ì¹  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.']
    
    def _extract_strategic_considerations_from_text(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì „ëµì  ê³ ë ¤ì‚¬í•­ ì¶”ì¶œ"""
        return ['ì „ëµì  ê´€ì ì—ì„œ ê³ ë ¤í•  ì‚¬í•­ë“¤ì´ ìˆìŠµë‹ˆë‹¤.']
    
    def _extract_competitive_advantage_from_text(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ê²½ìŸ ìš°ìœ„ ìš”ì†Œ ì¶”ì¶œ"""
        return ['ê²½ìŸ ìš°ìœ„ í™•ë³´ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.']
    
    def _extract_immediate_actions_from_text(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì¦‰ì‹œ ì‹¤í–‰ ì•¡ì…˜ ì¶”ì¶œ"""
        return ['ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì¹˜ì‚¬í•­ë“¤ì´ ìˆìŠµë‹ˆë‹¤.']
    
    def _extract_short_term_strategies_from_text(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ë‹¨ê¸° ì „ëµ ì¶”ì¶œ"""
        return ['ë‹¨ê¸° ì „ëµ ìˆ˜ë¦½ì´ í•„ìš”í•©ë‹ˆë‹¤.']
    
    def _extract_long_term_initiatives_from_text(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì¥ê¸° ì´ë‹ˆì…”í‹°ë¸Œ ì¶”ì¶œ"""
        return ['ì¥ê¸°ì  ê´€ì ì˜ ì´ë‹ˆì…”í‹°ë¸Œê°€ ê¶Œì¥ë©ë‹ˆë‹¤.']
    
    def _extract_risk_mitigation_from_text(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ìœ„í—˜ ì™„í™” ë°©ì•ˆ ì¶”ì¶œ"""
        return ['ë¦¬ìŠ¤í¬ ì™„í™” ë°©ì•ˆì„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.']
    
    def _extract_success_metrics_from_text(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì„±ê³µ ì§€í‘œ ì¶”ì¶œ"""
        return ['ì„±ê³µ ì¸¡ì •ì„ ìœ„í•œ ì§€í‘œê°€ í•„ìš”í•©ë‹ˆë‹¤.']
    
    def _assess_interpretation_reliability(self, interpretation: Dict, statistical_results: Dict,
                                         assumptions_report: Dict) -> Dict[str, Any]:
        """í•´ì„ ì‹ ë¢°ì„± í‰ê°€"""
        return {
            'confidence_level': 'high',
            'statistical_robustness': 'good',
            'assumption_validity': 'acceptable'
        }
    
    def _assess_insights_practicality(self, business_insights: Dict, rag_context: Dict) -> Dict[str, Any]:
        """ì¸ì‚¬ì´íŠ¸ ì‹¤ìš©ì„± í‰ê°€"""
        return {
            'actionability': 'high',
            'relevance': 'medium',
            'implementation_difficulty': 'low'
        }
    
    def _assess_recommendations_feasibility(self, recommendations: Dict, rag_context: Dict) -> Dict[str, Any]:
        """ê¶Œì¥ì‚¬í•­ ì‹¤í˜„ ê°€ëŠ¥ì„± í‰ê°€"""
        return {
            'feasibility_score': 0.8,
            'resource_requirements': 'medium',
            'timeline_realistic': True
        }
    
    def _assess_report_quality(self, report: Dict) -> float:
        """ë³´ê³ ì„œ í’ˆì§ˆ í‰ê°€"""
        # ê°„ë‹¨í•œ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        quality_factors = []
        
        if report.get('statistical_results'):
            quality_factors.append(0.3)
        if report.get('interpretation_and_insights'):
            quality_factors.append(0.3)
        if report.get('recommendations'):
            quality_factors.append(0.2)
        if report.get('visualizations'):
            quality_factors.append(0.2)
        
        return sum(quality_factors)
    
    def _display_report_summary(self, report: Dict, save_result: Dict) -> None:
        """ë³´ê³ ì„œ ìš”ì•½ í‘œì‹œ"""
        try:
            print("\n" + "="*60)
            print("ğŸ“ ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
            print("="*60)
            
            # ë³´ê³ ì„œ ë©”íƒ€ë°ì´í„°
            metadata = report.get('report_metadata', {})
            print(f"\nğŸ“‹ ë³´ê³ ì„œ ì œëª©: {metadata.get('title', 'Unknown')}")
            print(f"ğŸ¯ ë¶„ì„ ëª©ì : {metadata.get('user_request', 'Unknown')[:50]}...")
            print(f"ğŸ“Š ë¶„ì„ ë°©ë²•: {metadata.get('analysis_method', 'Unknown')}")
            
            # ì£¼ìš” ê²°ê³¼
            statistical_results = report.get('statistical_results', {})
            main_findings = statistical_results.get('main_findings', [])
            if main_findings:
                print(f"\nğŸ” ì£¼ìš” ë°œê²¬ì‚¬í•­:")
                for finding in main_findings[:2]:
                    print(f"   â€¢ {finding}")
            
            # ê¶Œì¥ì‚¬í•­
            recommendations = report.get('recommendations', {})
            immediate_actions = recommendations.get('immediate_actions', [])
            if immediate_actions:
                print(f"\nğŸ’¡ ì¦‰ì‹œ ì‹¤í–‰ ê¶Œì¥ì‚¬í•­:")
                for action in immediate_actions[:2]:
                    print(f"   â€¢ {action}")
            
            # ì €ì¥ ê²°ê³¼
            if save_result.get('success'):
                print(f"\nğŸ’¾ ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ:")
                for file_path in save_result.get('files_generated', []):
                    print(f"   â€¢ {file_path}")
            else:
                print(f"\nâŒ ë³´ê³ ì„œ ì €ì¥ ì‹¤íŒ¨: {save_result.get('error', 'Unknown error')}")
            
            print(f"\nâœ… 8ë‹¨ê³„ ì›Œí¬í”Œë¡œìš°ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            
        except Exception as e:
            self.logger.error(f"ë³´ê³ ì„œ ìš”ì•½ í‘œì‹œ ì˜¤ë¥˜: {e}")
    
    def get_step_info(self) -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ ì •ë³´ ë°˜í™˜"""
        return {
            'step_number': 8,
            'step_name': 'agent_reporting',
            'description': 'LLM AGENT ë³´ê³ ì„œ ìƒì„± (í•´ì„ ë° ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸)',
            'input_required': False,
            'input_type': 'automatic',
            'next_step': 'workflow_complete',
            'agentic_flow': True
        } 