"""
Analysis Proposal Pipeline

4ë‹¨ê³„: RAG ê¸°ë°˜ Agentic LLMì˜ ì§€ëŠ¥í˜• ë¶„ì„ ì „ëµ ì œì•ˆ
RAGë¥¼ í†µí•´ í™•ë³´í•œ í†µê³„ ì§€ì‹, ë„ë©”ì¸ ì§€ì‹, ì½”ë“œ í…œí”Œë¦¿ì„ LLM Agentê°€ ì™„ì „íˆ í†µí•©í•˜ì—¬
ë°ì´í„° íŠ¹ì„±ê³¼ ì‚¬ìš©ì ìš”êµ¬ì— ìµœì í™”ëœ ë¶„ì„ ì „ëµì„ ììœ¨ì ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
"""

import logging
from typing import Dict, Any, List, Optional
from pathlib import Path
import json

from .base_pipeline_step import BasePipelineStep, PipelineStepRegistry
from core.rag.rag_manager import RAGManager
from services.llm.llm_client import LLMClient
from services.llm.prompt_engine import PromptEngine


class AnalysisProposalStep(BasePipelineStep):
    """4ë‹¨ê³„: RAG ê¸°ë°˜ Agentic LLMì˜ ì§€ëŠ¥í˜• ë¶„ì„ ì „ëµ ì œì•ˆ"""
    
    def __init__(self):
        """AnalysisProposalStep ì´ˆê¸°í™”"""
        super().__init__("RAG ê¸°ë°˜ Agentic LLMì˜ ì§€ëŠ¥í˜• ë¶„ì„ ì „ëµ ì œì•ˆ", 4)
        self.rag_manager = RAGManager()
        self.llm_client = LLMClient()
        self.prompt_engine = PromptEngine()
        
        # Agent ì„¤ì •
        self.agent_config = {
            'analysis_creativity': 0.7,  # ë¶„ì„ ë°©ë²• ì°½ì˜ì„±
            'risk_tolerance': 0.3,       # ìœ„í—˜ í—ˆìš©ë„
            'explanation_depth': 'detailed',  # ì„¤ëª… ê¹Šì´
            'domain_focus': True         # ë„ë©”ì¸ íŠ¹í™” ë¶„ì„
        }
        
    def validate_input(self, input_data: Dict[str, Any]) -> bool:
        """
        ì…ë ¥ ë°ì´í„° ìœ íš¨ì„± ê²€ì¦
        
        Args:
            input_data: 3ë‹¨ê³„ì—ì„œ ì „ë‹¬ë°›ì€ ë°ì´í„°
            
        Returns:
            bool: ìœ íš¨ì„± ê²€ì¦ ê²°ê³¼
        """
        required_fields = [
            'agent_data_analysis', 'data_insights', 'quality_assessment',
            'analysis_recommendations', 'data_object'
        ]
        return all(field in input_data for field in required_fields)
    
    def get_expected_output_schema(self) -> Dict[str, Any]:
        """
        ì˜ˆìƒ ì¶œë ¥ ìŠ¤í‚¤ë§ˆ ë°˜í™˜
        
        Returns:
            Dict[str, Any]: ì¶œë ¥ ë°ì´í„° ìŠ¤í‚¤ë§ˆ
        """
        return {
            'agent_analysis_strategy': {
                'primary_recommendation': dict,
                'alternative_strategies': list,
                'strategy_rationale': dict,
                'confidence_scores': dict
            },
            'rag_integrated_insights': {
                'statistical_foundations': dict,
                'domain_best_practices': dict,
                'similar_cases': list,
                'methodological_guidance': dict
            },
            'adaptive_execution_plan': {
                'primary_path': dict,
                'fallback_scenarios': list,
                'dynamic_checkpoints': list,
                'adjustment_triggers': dict
            },
            'agent_reasoning_chain': {
                'decision_factors': list,
                'trade_off_analysis': dict,
                'assumption_validation': dict,
                'risk_assessment': dict
            },
            'contextual_recommendations': {
                'data_driven_insights': list,
                'domain_specific_advice': list,
                'implementation_guidelines': dict,
                'quality_assurance_plan': dict
            }
        }
    
    def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        RAG ê¸°ë°˜ Agentic LLMì˜ ì§€ëŠ¥í˜• ë¶„ì„ ì „ëµ ì œì•ˆ ì‹¤í–‰
        
        Args:
            input_data: íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸
            
        Returns:
            Dict: ì‹¤í–‰ ê²°ê³¼
        """
        self.logger.info("4ë‹¨ê³„: RAG ê¸°ë°˜ Agentic LLMì˜ ì§€ëŠ¥í˜• ë¶„ì„ ì „ëµ ì œì•ˆ ì‹œì‘")
        
        try:
            # 1. RAG ê¸°ë°˜ ì¢…í•© ì§€ì‹ ìˆ˜ì§‘ ë° í†µí•©
            rag_knowledge_context = self._collect_comprehensive_rag_knowledge(input_data)
            
            # 2. Agentì˜ ììœ¨ì  ë¶„ì„ ì „ëµ ìˆ˜ë¦½
            agent_analysis_strategy = self._generate_autonomous_analysis_strategy(
                input_data, rag_knowledge_context
            )
            
            # 3. RAG ì§€ì‹ê³¼ Agent ì¶”ë¡ ì˜ í†µí•©ëœ ì¸ì‚¬ì´íŠ¸
            rag_integrated_insights = self._integrate_rag_agent_insights(
                rag_knowledge_context, agent_analysis_strategy
            )
            
            # 4. ì ì‘í˜• ì‹¤í–‰ ê³„íš ìˆ˜ë¦½
            adaptive_execution_plan = self._create_adaptive_execution_plan(
                agent_analysis_strategy, rag_integrated_insights, input_data
            )
            
            # 5. Agent ì¶”ë¡  ê³¼ì • íˆ¬ëª…í™”
            agent_reasoning_chain = self._document_agent_reasoning(
                input_data, rag_knowledge_context, agent_analysis_strategy
            )
            
            # 6. ë§¥ë½ì  ì¶”ì²œì‚¬í•­ ìƒì„±
            contextual_recommendations = self._generate_contextual_recommendations(
                agent_analysis_strategy, rag_integrated_insights, input_data
            )
            
            self.logger.info("RAG ê¸°ë°˜ ì§€ëŠ¥í˜• ë¶„ì„ ì „ëµ ì œì•ˆ ì™„ë£Œ")
            
            return {
                'agent_analysis_strategy': agent_analysis_strategy,
                'rag_integrated_insights': rag_integrated_insights,
                'adaptive_execution_plan': adaptive_execution_plan,
                'agent_reasoning_chain': agent_reasoning_chain,
                'contextual_recommendations': contextual_recommendations,
                'success_message': "ğŸ¤– AI Agentê°€ RAG ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì ì˜ ë¶„ì„ ì „ëµì„ ìˆ˜ë¦½í–ˆìŠµë‹ˆë‹¤."
            }
                
        except Exception as e:
            self.logger.error(f"RAG ê¸°ë°˜ ë¶„ì„ ì „ëµ ì œì•ˆ ì˜¤ë¥˜: {e}")
            return {
                'error': True,
                'error_message': str(e),
                'error_type': 'agent_strategy_error'
            }
    
    def _collect_comprehensive_rag_knowledge(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """RAG ê¸°ë°˜ ì¢…í•© ì§€ì‹ ìˆ˜ì§‘ ë° í†µí•©"""
        try:
            # 1. ë‹¤ì¸µì  RAG ê²€ìƒ‰ ì „ëµ
            search_queries = self._build_multi_layer_search_queries(input_data)
            
            # 2. í†µê³„ ë°©ë²•ë¡  ì§€ì‹ ìˆ˜ì§‘
            statistical_knowledge = self.rag_manager.search_and_build_context(
                query=search_queries['statistical_methods'],
                collection="statistical_concepts",
                top_k=8,
                context_type="statistical_analysis",
                max_tokens=1500
            )
            
            # 3. ë„ë©”ì¸ ì „ë¬¸ ì§€ì‹ ìˆ˜ì§‘
            domain_knowledge = self.rag_manager.search_and_build_context(
                query=search_queries['domain_context'],
                collection="business_domains",
                top_k=5,
                context_type="domain_expertise",
                max_tokens=1000
            )
            
            # 4. ì½”ë“œ êµ¬í˜„ íŒ¨í„´ ìˆ˜ì§‘
            code_patterns = self.rag_manager.search_and_build_context(
                query=search_queries['implementation_patterns'],
                collection="code_templates",
                top_k=6,
                context_type="implementation_guidance",
                max_tokens=1200
            )
            
            # 5. ìœ ì‚¬ ì¼€ì´ìŠ¤ ìŠ¤í„°ë”” ê²€ìƒ‰
            similar_cases = self.rag_manager.search_and_build_context(
                query=search_queries['case_studies'],
                collection="case_studies",  # ìƒˆë¡œìš´ ì»¬ë ‰ì…˜
                top_k=4,
                context_type="case_analysis",
                max_tokens=800
            )
            
            # 6. ì§€ì‹ í†µí•© ë° ì¤‘ìš”ë„ ê°€ì¤‘ì¹˜ ë¶€ì—¬
            integrated_knowledge = self._integrate_knowledge_with_weights({
                'statistical_knowledge': statistical_knowledge,
                'domain_knowledge': domain_knowledge,
                'code_patterns': code_patterns,
                'similar_cases': similar_cases
            })
            
            return integrated_knowledge
            
        except Exception as e:
            self.logger.error(f"RAG ì§€ì‹ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return self._create_fallback_knowledge_context()
    
    def _build_multi_layer_search_queries(self, input_data: Dict[str, Any]) -> Dict[str, str]:
        """ë‹¤ì¸µì  RAG ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±"""
        # ë°ì´í„° íŠ¹ì„± ì¶”ì¶œ
        data_characteristics = input_data.get('summary_insights', {}).get('data_characteristics', [])
        variable_types = input_data.get('variable_analysis', {})
        user_intent = input_data.get('user_request', '')
        recommended_analyses = input_data.get('analysis_recommendations', {}).get('suitable_analyses', [])
        
        return {
            'statistical_methods': f"""
            ë°ì´í„° íŠ¹ì„±: {', '.join(data_characteristics)}
            ë³€ìˆ˜ ìœ í˜•: {json.dumps(variable_types, ensure_ascii=False)}
            ì¶”ì²œ ë¶„ì„: {', '.join(recommended_analyses)}
            í†µê³„ì  ê°€ì • ê²€ì¦, íš¨ê³¼ í¬ê¸°, ê²€ì •ë ¥ ë¶„ì„, ì‚¬í›„ ê²€ì •
            """,
            
            'domain_context': f"""
            ë¶„ì„ ëª©ì : {user_intent}
            ë°ì´í„° ë„ë©”ì¸ íŠ¹ì„±: {', '.join(data_characteristics)}
            ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸, ë„ë©”ì¸ë³„ ë¶„ì„ íŒ¨í„´, KPI í•´ì„
            """,
            
            'implementation_patterns': f"""
            êµ¬í˜„ ë°©ë²•: {', '.join(recommended_analyses)}
            ë°ì´í„° ì „ì²˜ë¦¬, ì½”ë“œ êµ¬ì¡°, ì˜¤ë¥˜ ì²˜ë¦¬, ê²°ê³¼ ê²€ì¦
            Python í†µê³„ ë¶„ì„, pandas, scipy, statsmodels
            """,
            
            'case_studies': f"""
            ìœ ì‚¬ ë¶„ì„ ì‚¬ë¡€: {user_intent}
            ë°ì´í„° í¬ê¸° ë° íŠ¹ì„±: {', '.join(data_characteristics)}
            ì„±ê³µ ì‚¬ë¡€, ì‹¤íŒ¨ ìš”ì¸, í•´ê²° ë°©ì•ˆ
            """
        }
    
    def _integrate_knowledge_with_weights(self, knowledge_sources: Dict[str, Any]) -> Dict[str, Any]:
        """ì§€ì‹ ì†ŒìŠ¤ë³„ ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•œ í†µí•©"""
        # ì§€ì‹ ìœ í˜•ë³„ ê°€ì¤‘ì¹˜
        weights = {
            'statistical_knowledge': 0.35,
            'domain_knowledge': 0.25,
            'code_patterns': 0.25,
            'similar_cases': 0.15
        }
        
        integrated = {
            'weighted_contexts': {},
            'combined_insights': [],
            'cross_references': {},
            'confidence_metrics': {}
        }
        
        for source_name, source_data in knowledge_sources.items():
            weight = weights.get(source_name, 0.2)
            
            # ê°€ì¤‘ì¹˜ ì ìš©ëœ ì»¨í…ìŠ¤íŠ¸ ì €ì¥
            integrated['weighted_contexts'][source_name] = {
                'context': source_data.get('context', ''),
                'search_results': source_data.get('search_results', []),
                'weight': weight,
                'relevance_score': self._calculate_relevance_score(source_data)
            }
            
            # ì£¼ìš” ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
            insights = self._extract_key_insights(source_data, weight)
            integrated['combined_insights'].extend(insights)
        
        # êµì°¨ ì°¸ì¡° êµ¬ì¶•
        integrated['cross_references'] = self._build_cross_references(knowledge_sources)
        
        return integrated
    
    def _calculate_relevance_score(self, source_data: Dict[str, Any]) -> float:
        """ì†ŒìŠ¤ ë°ì´í„°ì˜ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°"""
        try:
            search_results = source_data.get('search_results', [])
            if not search_results:
                return 0.0
            
            # ê²°ê³¼ ê°œìˆ˜ì™€ í’ˆì§ˆì„ ê¸°ë°˜ìœ¼ë¡œ ì ìˆ˜ ê³„ì‚°
            num_results = len(search_results)
            avg_score = sum(result.get('similarity_score', 0.0) for result in search_results) / num_results
            
            # 0.0-1.0 ë²”ìœ„ë¡œ ì •ê·œí™”
            return min(avg_score, 1.0)
            
        except Exception:
            return 0.5  # ê¸°ë³¸ê°’
    
    def _extract_key_insights(self, source_data: Dict[str, Any], weight: float) -> List[str]:
        """ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ ì£¼ìš” ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        try:
            insights = []
            search_results = source_data.get('search_results', [])
            
            for result in search_results[:3]:  # ìƒìœ„ 3ê°œ ê²°ê³¼ë§Œ ì‚¬ìš©
                content = result.get('content', '')
                if content and len(content) > 50:  # ì˜ë¯¸ìˆëŠ” ë‚´ìš©ë§Œ
                    insight = f"[ê°€ì¤‘ì¹˜: {weight:.2f}] {content[:200]}..."
                    insights.append(insight)
            
            return insights
            
        except Exception:
            return []
    
    def _build_cross_references(self, knowledge_sources: Dict[str, Any]) -> Dict[str, Any]:
        """ì§€ì‹ ì†ŒìŠ¤ ê°„ êµì°¨ ì°¸ì¡° êµ¬ì¶•"""
        try:
            cross_refs = {
                'statistical_domain_overlap': [],
                'implementation_statistical_overlap': [],
                'case_domain_overlap': [],
                'common_themes': []
            }
            
            # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ êµì°¨ ì°¸ì¡°
            all_contents = {}
            for source_name, source_data in knowledge_sources.items():
                contents = []
                for result in source_data.get('search_results', []):
                    contents.append(result.get('content', ''))
                all_contents[source_name] = ' '.join(contents).lower()
            
            # ê³µí†µ í…Œë§ˆ ì¶”ì¶œ (ì˜ˆì‹œ)
            common_keywords = ['ë¶„ì„', 'í†µê³„', 'ê²€ì •', 'ë°ì´í„°', 'ë³€ìˆ˜']
            for keyword in common_keywords:
                sources_with_keyword = [name for name, content in all_contents.items() 
                                      if keyword in content]
                if len(sources_with_keyword) > 1:
                    cross_refs['common_themes'].append({
                        'theme': keyword,
                        'sources': sources_with_keyword
                    })
            
            return cross_refs
            
        except Exception:
            return {}
    
    def _generate_autonomous_analysis_strategy(self, input_data: Dict[str, Any], 
                                             rag_knowledge: Dict[str, Any]) -> Dict[str, Any]:
        """Agentì˜ ììœ¨ì  ë¶„ì„ ì „ëµ ìˆ˜ë¦½"""
        try:
            # 1. RAG ì§€ì‹ì„ í†µí•©í•œ Agent í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            agent_prompt = self._build_autonomous_agent_prompt(input_data, rag_knowledge)
            
            # 2. Agentì˜ ììœ¨ì  ì¶”ë¡  ì‹¤í–‰
            agent_response = self.llm_client.generate_response(
                prompt=agent_prompt,
                temperature=self.agent_config['analysis_creativity'],
                max_tokens=3000,
                system_prompt=self._get_agent_system_prompt()
            )
            
            # 3. Agent ì‘ë‹µ êµ¬ì¡°í™”
            strategy = self._parse_agent_strategy_response(agent_response)
            
            # 4. ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°
            confidence_scores = self._calculate_strategy_confidence(
                strategy, rag_knowledge, input_data
            )
            
            # 5. ì „ëµ ê²€ì¦ ë° ë³´ì™„
            validated_strategy = self._validate_and_enhance_strategy(
                strategy, confidence_scores, rag_knowledge
            )
            
            return validated_strategy
            
        except Exception as e:
            self.logger.error(f"Agent ì „ëµ ìˆ˜ë¦½ ì˜¤ë¥˜: {e}")
            return self._create_fallback_strategy(input_data)
    
    def _build_autonomous_agent_prompt(self, input_data: Dict[str, Any], 
                                     rag_knowledge: Dict[str, Any]) -> str:
        """RAG ì§€ì‹ì„ í†µí•©í•œ Agent í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        
        # RAG ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
        statistical_context = rag_knowledge.get('weighted_contexts', {}).get('statistical_knowledge', {}).get('context', '')
        domain_context = rag_knowledge.get('weighted_contexts', {}).get('domain_knowledge', {}).get('context', '')
        code_context = rag_knowledge.get('weighted_contexts', {}).get('code_patterns', {}).get('context', '')
        case_context = rag_knowledge.get('weighted_contexts', {}).get('similar_cases', {}).get('context', '')
        
        prompt = f"""
ë‹¹ì‹ ì€ RAG ì§€ì‹ì„ í™œìš©í•˜ëŠ” ì „ë¬¸ í†µê³„ ë¶„ì„ AI Agentì…ë‹ˆë‹¤. 
ì œê³µëœ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë°ì´í„°ì— ìµœì í™”ëœ ë¶„ì„ ì „ëµì„ ììœ¨ì ìœ¼ë¡œ ìˆ˜ë¦½í•˜ì„¸ìš”.

## ë°ì´í„° ì»¨í…ìŠ¤íŠ¸
{json.dumps(input_data.get('data_overview', {}), ensure_ascii=False, indent=2)}

## ë³€ìˆ˜ ë¶„ì„ ê²°ê³¼
{json.dumps(input_data.get('variable_analysis', {}), ensure_ascii=False, indent=2)}

## ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­
{input_data.get('user_request', 'ëª…ì‹œë˜ì§€ ì•ŠìŒ')}

## RAG ì§€ì‹ ë² ì´ìŠ¤

### í†µê³„ ë°©ë²•ë¡  ì§€ì‹
{statistical_context}

### ë„ë©”ì¸ ì „ë¬¸ ì§€ì‹
{domain_context}

### êµ¬í˜„ íŒ¨í„´ ê°€ì´ë“œ
{code_context}

### ìœ ì‚¬ ì‚¬ë¡€ ë¶„ì„
{case_context}

## Agent ì„ë¬´
ìœ„ì˜ ëª¨ë“  ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ë‹¤ìŒì„ ììœ¨ì ìœ¼ë¡œ ê²°ì •í•˜ì„¸ìš”:

1. **ì£¼ ë¶„ì„ ì „ëµ**: RAG ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ìµœì  ë¶„ì„ ë°©ë²•
2. **ëŒ€ì•ˆ ì „ëµë“¤**: ë¦¬ìŠ¤í¬ ê´€ë¦¬ë¥¼ ìœ„í•œ ëŒ€ì²´ ë°©ì•ˆë“¤
3. **ì „ëµë³„ ê·¼ê±°**: ê° ì„ íƒì˜ í†µê³„ì /ë„ë©”ì¸ì  ê·¼ê±°
4. **ì‹¤í–‰ ìš°ì„ ìˆœìœ„**: íš¨ìœ¨ì„±ê³¼ ì •í™•ì„±ì„ ê³ ë ¤í•œ ìˆœì„œ
5. **ì ì‘ ê³„íš**: ì¤‘ê°„ ê²°ê³¼ì— ë”°ë¥¸ ë™ì  ì¡°ì • ë°©ì•ˆ

ì‘ë‹µì€ JSON í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”í•˜ì—¬ ì œê³µí•˜ì„¸ìš”.
        """
        
        return prompt
    
    def _get_agent_system_prompt(self) -> str:
        """Agent ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"""
        return """
ë‹¹ì‹ ì€ ê³ ë„ë¡œ í›ˆë ¨ëœ í†µê³„ ë¶„ì„ ì „ë¬¸ AI Agentì…ë‹ˆë‹¤.

í•µì‹¬ ì›ì¹™:
1. RAG ì§€ì‹ì„ ë¶„ì„ íŒë‹¨ì˜ í•µì‹¬ ê·¼ê±°ë¡œ í™œìš©
2. ë°ì´í„° íŠ¹ì„±ì— ë§ëŠ” ìµœì í™”ëœ ì ‘ê·¼ë²• ì„ íƒ
3. ë¶ˆí™•ì‹¤ì„±ê³¼ ë¦¬ìŠ¤í¬ë¥¼ ëª…í™•íˆ ì¸ì‹í•˜ê³  ê´€ë¦¬
4. ë‹¨ê³„ì ì´ê³  ë…¼ë¦¬ì ì¸ ì¶”ë¡  ê³¼ì • ìœ ì§€
5. ë„ë©”ì¸ ë§¥ë½ì„ ê³ ë ¤í•œ ì‹¤ìš©ì  ì†”ë£¨ì…˜ ì œì‹œ

ë¶„ì„ ê²°ì • ì‹œ ê³ ë ¤ì‚¬í•­:
- í†µê³„ì  ê°€ì •ì˜ ë§Œì¡± ì—¬ë¶€
- ìƒ˜í”Œ í¬ê¸°ì˜ ì ì ˆì„±
- íš¨ê³¼ í¬ê¸°ì˜ ì‹¤ìš©ì  ì˜ë¯¸
- ë„ë©”ì¸ë³„ í•´ì„ ê¸°ì¤€
- êµ¬í˜„ ë³µì¡ë„ì™€ ì‹ ë¢°ì„±ì˜ ê· í˜•
        """
    
    def _parse_agent_strategy_response(self, response: str) -> Dict[str, Any]:
        """Agent ì‘ë‹µì„ êµ¬ì¡°í™”ëœ ì „ëµìœ¼ë¡œ íŒŒì‹±"""
        try:
            # JSON ì‘ë‹µ íŒŒì‹± ì‹œë„
            if '{' in response and '}' in response:
                json_part = response[response.find('{'):response.rfind('}')+1]
                parsed = json.loads(json_part)
                return self._validate_strategy_structure(parsed)
            else:
                # í…ìŠ¤íŠ¸ ì‘ë‹µ íŒŒì‹±
                return self._parse_text_strategy_response(response)
                
        except Exception as e:
            self.logger.warning(f"Agent ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨, í´ë°± ì²˜ë¦¬: {e}")
            return self._extract_strategy_from_text(response)
    
    def _validate_strategy_structure(self, strategy: Dict[str, Any]) -> Dict[str, Any]:
        """ì „ëµ êµ¬ì¡° ê²€ì¦ ë° ë³´ì™„"""
        required_fields = {
            'primary_recommendation': {},
            'alternative_strategies': [],
            'strategy_rationale': {},
            'confidence_scores': {}
        }
        
        for field, default in required_fields.items():
            if field not in strategy:
                strategy[field] = default
                
        return strategy
    
    def _calculate_strategy_confidence(self, strategy: Dict[str, Any],
                                     rag_knowledge: Dict[str, Any],
                                     input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì „ëµë³„ ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°"""
        confidence_metrics = {
            'rag_knowledge_alignment': 0.0,
            'data_suitability': 0.0,
            'methodological_soundness': 0.0,
            'implementation_feasibility': 0.0,
            'overall_confidence': 0.0
        }
        
        try:
            # RAG ì§€ì‹ ì •ë ¬ë„ í‰ê°€
            confidence_metrics['rag_knowledge_alignment'] = self._assess_rag_alignment(
                strategy, rag_knowledge
            )
            
            # ë°ì´í„° ì í•©ì„± í‰ê°€
            confidence_metrics['data_suitability'] = self._assess_data_suitability(
                strategy, input_data
            )
            
            # ë°©ë²•ë¡ ì  ê±´ì „ì„± í‰ê°€
            confidence_metrics['methodological_soundness'] = self._assess_methodological_soundness(
                strategy, rag_knowledge
            )
            
            # êµ¬í˜„ ê°€ëŠ¥ì„± í‰ê°€
            confidence_metrics['implementation_feasibility'] = self._assess_implementation_feasibility(
                strategy, rag_knowledge
            )
            
            # ì „ì²´ ì‹ ë¢°ë„ ê³„ì‚°
            weights = [0.3, 0.3, 0.25, 0.15]
            scores = [confidence_metrics[key] for key in list(confidence_metrics.keys())[:-1]]
            confidence_metrics['overall_confidence'] = sum(w * s for w, s in zip(weights, scores))
            
        except Exception as e:
            self.logger.error(f"ì‹ ë¢°ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
            
        return confidence_metrics

    def _create_fallback_knowledge_context(self) -> Dict[str, Any]:
        """ë¹ˆ ì»¨í…ìŠ¤íŠ¸ ë°˜í™˜"""
        return {
            'weighted_contexts': {},
            'combined_insights': [],
            'cross_references': {},
            'confidence_metrics': {}
        }

    def _create_fallback_strategy(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ê¸°ë³¸ ì „ëµ ë°˜í™˜"""
        return {
            'primary_recommendation': 'ê¸°ë³¸ ë¶„ì„',
            'alternative_strategies': [],
            'strategy_rationale': {},
            'confidence_scores': {}
        }

    def _assess_rag_alignment(self, strategy: Dict[str, Any],
                             rag_knowledge: Dict[str, Any]) -> float:
        """RAG ì§€ì‹ ì •ë ¬ë„ í‰ê°€"""
        # êµ¬í˜„ í•„ìš”
        return 0.5

    def _assess_data_suitability(self, strategy: Dict[str, Any],
                                 input_data: Dict[str, Any]) -> float:
        """ë°ì´í„° ì í•©ì„± í‰ê°€"""
        # êµ¬í˜„ í•„ìš”
        return 0.5

    def _assess_methodological_soundness(self, strategy: Dict[str, Any],
                                         rag_knowledge: Dict[str, Any]) -> float:
        """ë°©ë²•ë¡ ì  ê±´ì „ì„± í‰ê°€"""
        # êµ¬í˜„ í•„ìš”
        return 0.5

    def _assess_implementation_feasibility(self, strategy: Dict[str, Any],
                                           rag_knowledge: Dict[str, Any]) -> float:
        """êµ¬í˜„ ê°€ëŠ¥ì„± í‰ê°€"""
        # êµ¬í˜„ í•„ìš”
        return 0.5

    def _extract_strategy_from_text(self, text: str) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ ê¸°ë°˜ ê¸°ë³¸ ì „ëµ ì¶”ì¶œ"""
        # êµ¬í˜„ í•„ìš”
        return {
            'primary_recommendation': 'ê¸°ë³¸ ë¶„ì„',
            'alternative_strategies': [],
            'strategy_rationale': {},
            'confidence_scores': {}
        }

    def _validate_and_enhance_strategy(self, strategy: Dict[str, Any],
                                     confidence_scores: Dict[str, Any],
                                     rag_knowledge: Dict[str, Any]) -> Dict[str, Any]:
        """ì „ëµ ê²€ì¦ ë° ë³´ì™„"""
        # êµ¬í˜„ í•„ìš”
        return strategy

    def _integrate_rag_agent_insights(self, rag_knowledge: Dict[str, Any],
                                     agent_strategy: Dict[str, Any]) -> Dict[str, Any]:
        """RAG ì§€ì‹ê³¼ Agent ì¶”ë¡ ì˜ í†µí•©ëœ ì¸ì‚¬ì´íŠ¸"""
        # êµ¬í˜„ í•„ìš”
        return {
            'statistical_foundations': {},
            'domain_best_practices': {},
            'similar_cases': [],
            'methodological_guidance': {}
        }

    def _create_adaptive_execution_plan(self, agent_strategy: Dict[str, Any],
                                     rag_integrated_insights: Dict[str, Any],
                                     input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì ì‘í˜• ì‹¤í–‰ ê³„íš ìˆ˜ë¦½"""
        # êµ¬í˜„ í•„ìš”
        return {
            'primary_path': {},
            'fallback_scenarios': [],
            'dynamic_checkpoints': [],
            'adjustment_triggers': {}
        }

    def _document_agent_reasoning(self, input_data: Dict[str, Any],
                                 rag_knowledge: Dict[str, Any],
                                 agent_strategy: Dict[str, Any]) -> Dict[str, Any]:
        """Agent ì¶”ë¡  ê³¼ì • íˆ¬ëª…í™”"""
        # êµ¬í˜„ í•„ìš”
        return {
            'decision_factors': [],
            'trade_off_analysis': {},
            'assumption_validation': {},
            'risk_assessment': {}
        }

    def _generate_contextual_recommendations(self, agent_strategy: Dict[str, Any],
                                           rag_integrated_insights: Dict[str, Any],
                                           input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ë§¥ë½ì  ì¶”ì²œì‚¬í•­ ìƒì„±"""
        # êµ¬í˜„ í•„ìš”
        return {
            'data_driven_insights': [],
            'domain_specific_advice': [],
            'implementation_guidelines': {},
            'quality_assurance_plan': {}
        }

    def get_step_info(self) -> Dict[str, Any]:
        """ë‹¨ê³„ ì •ë³´ ë°˜í™˜"""
        return {
            'step_number': 4,
            'step_name': 'analysis_proposal',
            'description': 'RAG ê¸°ë°˜ Agentic LLMì˜ ì§€ëŠ¥í˜• ë¶„ì„ ì „ëµ ì œì•ˆ',
            'input_requirements': [
                'user_request',
                'data_overview', 
                'data_quality_assessment',
                'variable_analysis',
                'analysis_recommendations'
            ],
            'output_format': {
                'agent_analysis_strategy': 'Dict',
                'rag_integrated_insights': 'Dict', 
                'adaptive_execution_plan': 'Dict',
                'agent_reasoning_chain': 'Dict',
                'contextual_recommendations': 'Dict'
            },
            'estimated_duration': '3-5 minutes'
        }


