"""
User Selection Pipeline

5ë‹¨ê³„: RAG ê¸°ë°˜ ëŒ€í™”í˜• ì‚¬ìš©ì ì˜ì‚¬ê²°ì • ì§€ì›
Agentê°€ RAG ì§€ì‹ì„ í™œìš©í•˜ì—¬ ì‚¬ìš©ìì™€ ì§€ëŠ¥í˜• ëŒ€í™”ë¥¼ í†µí•´
ìµœì ì˜ ë¶„ì„ ë°©ë²•ì„ ì„ íƒí•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•˜ë©°, ì‚¬ìš©ìì˜ ì˜ì‚¬ê²°ì •ì„ 
ë„ë©”ì¸ ì§€ì‹ê³¼ í†µê³„ì  ê·¼ê±°ë¡œ ë’·ë°›ì¹¨í•©ë‹ˆë‹¤.
"""

import logging
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path
import json
import asyncio

from .base_pipeline_step import BasePipelineStep, PipelineStepRegistry
from core.rag.rag_manager import RAGManager
from services.llm.llm_client import LLMClient
from services.llm.prompt_engine import PromptEngine
from utils.ui_helpers import UIHelpers


class UserSelectionStep(BasePipelineStep):
    """5ë‹¨ê³„: RAG ê¸°ë°˜ ëŒ€í™”í˜• ì‚¬ìš©ì ì˜ì‚¬ê²°ì • ì§€ì›"""
    
    def __init__(self):
        """UserSelectionStep ì´ˆê¸°í™”"""
        super().__init__("RAG ê¸°ë°˜ ëŒ€í™”í˜• ì‚¬ìš©ì ì˜ì‚¬ê²°ì • ì§€ì›", 5)
        self.rag_manager = RAGManager()
        self.llm_client = LLMClient()
        self.prompt_engine = PromptEngine()
        self.ui_helpers = UIHelpers()
        
        # ëŒ€í™”í˜• Agent ì„¤ì •
        self.conversation_config = {
            'max_conversation_turns': 5,
            'explanation_depth': 'adaptive',  # ì‚¬ìš©ì ìˆ˜ì¤€ì— ë§ì¶° ì¡°ì •
            'decision_support_mode': 'collaborative',  # í˜‘ë ¥ì  ì˜ì‚¬ê²°ì •
            'rag_integration_level': 'deep',  # ê¹Šì€ RAG í†µí•©
            'personalization_level': 'medium'  # ì‚¬ìš©ì ë§ì¶¤í™”
        }
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥
        self.conversation_history = []
        
    def validate_input(self, input_data: Dict[str, Any]) -> bool:
        """
        ì…ë ¥ ë°ì´í„° ìœ íš¨ì„± ê²€ì¦
        
        Args:
            input_data: 4ë‹¨ê³„ì—ì„œ ì „ë‹¬ë°›ì€ ë°ì´í„°
            
        Returns:
            bool: ìœ íš¨ì„± ê²€ì¦ ê²°ê³¼
        """
        required_fields = [
            'agent_analysis_strategy', 'rag_integrated_insights',
            'adaptive_execution_plan', 'agent_reasoning_chain'
        ]
        return all(field in input_data for field in required_fields)
    
    def get_expected_output_schema(self) -> Dict[str, Any]:
        """
        ì˜ˆìƒ ì¶œë ¥ ìŠ¤í‚¤ë§ˆ ë°˜í™˜
        
        Returns:
            Dict[str, Any]: ì¶œë ¥ ë°ì´í„° ìŠ¤í‚¤ë§ˆ
        """
        return {
            'finalized_analysis_plan': {
                'selected_primary_method': dict,
                'confirmed_alternatives': list,
                'execution_parameters': dict,
                'user_preferences': dict
            },
            'enhanced_rag_context': {
                'targeted_domain_knowledge': dict,
                'method_specific_guidance': dict,
                'user_context_insights': dict,
                'risk_mitigation_strategies': list
            },
            'collaborative_decision_record': {
                'conversation_summary': dict,
                'decision_rationale': dict,
                'agent_recommendations': dict,
                'user_feedback_integration': dict
            },
            'adaptive_execution_adjustments': {
                'customized_parameters': dict,
                'dynamic_checkpoints': list,
                'quality_assurance_plan': dict,
                'contingency_protocols': dict
            },
            'knowledge_driven_insights': {
                'domain_specific_considerations': list,
                'methodological_best_practices': list,
                'implementation_guidance': dict,
                'expected_outcomes': dict
            }
        }
    
    def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        RAG ê¸°ë°˜ ëŒ€í™”í˜• ì‚¬ìš©ì ì˜ì‚¬ê²°ì • ì§€ì› ì‹¤í–‰
        
        Args:
            input_data: íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸
            
        Returns:
            Dict: ì‹¤í–‰ ê²°ê³¼
        """
        self.logger.info("5ë‹¨ê³„: RAG ê¸°ë°˜ ëŒ€í™”í˜• ì‚¬ìš©ì ì˜ì‚¬ê²°ì • ì§€ì› ì‹œì‘")
        
        try:
            # 1. ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ë° RAG ì§€ì‹ ë§ì¶¤í™”
            personalized_rag_context = self._create_personalized_rag_context(input_data)
            
            # 2. ëŒ€í™”í˜• ì˜ì‚¬ê²°ì • í”„ë¡œì„¸ìŠ¤ ì§„í–‰
            conversation_result = self._conduct_collaborative_decision_process(
                input_data, personalized_rag_context
            )
            
            # 3. ìµœì¢… ë¶„ì„ ê³„íš í™•ì •
            finalized_analysis_plan = self._finalize_analysis_plan(
                conversation_result, input_data, personalized_rag_context
            )
            
            # 4. RAG ì§€ì‹ ê¸°ë°˜ ì‹¤í–‰ ì¡°ì •ì‚¬í•­ ìƒì„±
            adaptive_execution_adjustments = self._generate_adaptive_adjustments(
                finalized_analysis_plan, personalized_rag_context, conversation_result
            )
            
            # 5. ì˜ì‚¬ê²°ì • ê³¼ì • ë¬¸ì„œí™”
            collaborative_decision_record = self._document_decision_process(
                conversation_result, finalized_analysis_plan, input_data
            )
            
            # 6. ì§€ì‹ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ìƒì„±
            knowledge_driven_insights = self._generate_knowledge_insights(
                finalized_analysis_plan, personalized_rag_context, conversation_result
            )
            
            self.logger.info("RAG ê¸°ë°˜ ëŒ€í™”í˜• ì˜ì‚¬ê²°ì • ì§€ì› ì™„ë£Œ")
            
            return {
                'finalized_analysis_plan': finalized_analysis_plan,
                'enhanced_rag_context': personalized_rag_context,
                'collaborative_decision_record': collaborative_decision_record,
                'adaptive_execution_adjustments': adaptive_execution_adjustments,
                'knowledge_driven_insights': knowledge_driven_insights,
                'success_message': "ğŸ¤ ì‚¬ìš©ìì™€ AI Agentê°€ í˜‘ë ¥í•˜ì—¬ ìµœì ì˜ ë¶„ì„ ê³„íšì„ ìˆ˜ë¦½í–ˆìŠµë‹ˆë‹¤."
            }
                
        except Exception as e:
            self.logger.error(f"RAG ê¸°ë°˜ ëŒ€í™”í˜• ì˜ì‚¬ê²°ì • ì§€ì› ì˜¤ë¥˜: {e}")
            return {
                'error': True,
                'error_message': str(e),
                'error_type': 'collaborative_decision_error'
            }
    
    def _create_personalized_rag_context(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ë° RAG ì§€ì‹ ë§ì¶¤í™”"""
        try:
            # 1. ì‚¬ìš©ì ë°°ê²½ ë° ì„ í˜¸ë„ ë¶„ì„
            user_profile = self._analyze_user_context(input_data)
            
            # 2. ë§ì¶¤í˜• RAG ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
            personalized_queries = self._build_personalized_search_queries(
                input_data, user_profile
            )
            
            # 3. íƒ€ê²Ÿ ë„ë©”ì¸ ì§€ì‹ ìˆ˜ì§‘
            targeted_domain_knowledge = self.rag_manager.search_and_build_context(
                query=personalized_queries['domain_specific'],
                collection="business_domains",
                top_k=6,
                context_type="user_domain_guidance",
                max_tokens=1200
            )
            
            # 4. ë°©ë²•ë¡ ë³„ ìƒì„¸ ê°€ì´ë˜ìŠ¤ ìˆ˜ì§‘
            method_specific_guidance = self.rag_manager.search_and_build_context(
                query=personalized_queries['methodological'],
                collection="statistical_concepts",
                top_k=8,
                context_type="method_selection_guidance",
                max_tokens=1500
            )
            
            # 5. ì‚¬ìš©ì ë§¥ë½ ì¸ì‚¬ì´íŠ¸ ìƒì„±
            user_context_insights = self._generate_user_context_insights(
                user_profile, targeted_domain_knowledge, method_specific_guidance
            )
            
            # 6. ë¦¬ìŠ¤í¬ ì™„í™” ì „ëµ ìˆ˜ì§‘
            risk_mitigation_strategies = self._collect_risk_mitigation_strategies(
                input_data, personalized_queries
            )
            
            return {
                'targeted_domain_knowledge': targeted_domain_knowledge,
                'method_specific_guidance': method_specific_guidance,
                'user_context_insights': user_context_insights,
                'risk_mitigation_strategies': risk_mitigation_strategies,
                'user_profile': user_profile
            }
            
        except Exception as e:
            self.logger.error(f"ê°œì¸í™”ëœ RAG ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
            return self._create_default_rag_context()
    
    def _conduct_collaborative_decision_process(self, input_data: Dict[str, Any],
                                              rag_context: Dict[str, Any]) -> Dict[str, Any]:
        """ëŒ€í™”í˜• ì˜ì‚¬ê²°ì • í”„ë¡œì„¸ìŠ¤ ì§„í–‰"""
        try:
            # 1. ëŒ€í™” ì„¸ì…˜ ì´ˆê¸°í™”
            conversation_state = self._initialize_conversation_state(input_data, rag_context)
            
            # 2. Agentì˜ ì´ˆê¸° ì œì•ˆ ë° ì„¤ëª…
            initial_presentation = self._present_agent_recommendations(
                input_data, rag_context, conversation_state
            )
            
            # 3. ì‚¬ìš©ìì™€ì˜ ëŒ€í™”í˜• ìƒí˜¸ì‘ìš©
            conversation_turns = []
            current_turn = 1
            
            while current_turn <= self.conversation_config['max_conversation_turns']:
                # ì‚¬ìš©ì ì‘ë‹µ ìˆ˜ì§‘
                user_response = self._collect_user_response(
                    initial_presentation if current_turn == 1 else conversation_turns[-1]['agent_message'],
                    conversation_state,
                    current_turn
                )
                
                if user_response.get('decision_finalized', False):
                    conversation_turns.append({
                        'turn': current_turn,
                        'user_response': user_response,
                        'decision_status': 'finalized'
                    })
                    break
                
                # Agentì˜ ì ì‘ì  ì‘ë‹µ ìƒì„±
                agent_response = self._generate_adaptive_agent_response(
                    user_response, conversation_state, rag_context, current_turn
                )
                
                conversation_turns.append({
                    'turn': current_turn,
                    'user_response': user_response,
                    'agent_message': agent_response,
                    'conversation_state': conversation_state.copy()
                })
                
                # ëŒ€í™” ìƒíƒœ ì—…ë°ì´íŠ¸
                conversation_state = self._update_conversation_state(
                    conversation_state, user_response, agent_response
                )
                
                current_turn += 1
            
            # 4. ëŒ€í™” ê²°ê³¼ ì¢…í•©
            conversation_summary = self._summarize_conversation(
                conversation_turns, initial_presentation, conversation_state
            )
            
            return {
                'initial_presentation': initial_presentation,
                'conversation_turns': conversation_turns,
                'conversation_summary': conversation_summary,
                'final_state': conversation_state
            }
            
        except Exception as e:
            self.logger.error(f"ëŒ€í™”í˜• ì˜ì‚¬ê²°ì • í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜: {e}")
            return self._create_fallback_conversation_result(input_data)
    
    def _analyze_user_context(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì‚¬ìš©ì ë°°ê²½ ë° ì„ í˜¸ë„ ë¶„ì„"""
        try:
            # ì‚¬ìš©ì ìš”ì²­ì—ì„œ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
            user_request = input_data.get('user_request', '')
            data_overview = input_data.get('data_overview', {})
            
            # ë„ë©”ì¸ ì‹ë³„
            domain_indicators = {
                'healthcare': ['í™˜ì', 'ì¹˜ë£Œ', 'ë³‘ì›', 'ì˜ë£Œ', 'ì§„ë£Œ', 'ìˆ˜ìˆ ', 'ì•½ë¬¼'],
                'finance': ['ë§¤ì¶œ', 'ìˆ˜ìµ', 'ë¹„ìš©', 'íˆ¬ì', 'ê¸ˆìœµ', 'ì£¼ê°€', 'ê²½ì œ'],
                'marketing': ['ê´‘ê³ ', 'ë§ˆì¼€íŒ…', 'ê³ ê°', 'ìº í˜ì¸', 'ë¸Œëœë“œ', 'íŒë§¤'],
                'education': ['í•™ìƒ', 'êµìœ¡', 'í•™ìŠµ', 'ì„±ì ', 'ì‹œí—˜', 'ê³¼ëª©', 'í•™êµ'],
                'research': ['ì‹¤í—˜', 'ì—°êµ¬', 'ê°€ì„¤', 'ë³€ìˆ˜', 'ì¸¡ì •', 'ë¶„ì„', 'ê²°ê³¼']
            }
            
            identified_domain = 'general'
            for domain, keywords in domain_indicators.items():
                if any(keyword in user_request for keyword in keywords):
                    identified_domain = domain
                    break
            
            # ê¸°ìˆ  ìˆ˜ì¤€ ì¶”ì •
            technical_indicators = ['p-value', 'ì‹ ë¢°êµ¬ê°„', 'íš¨ê³¼í¬ê¸°', 'ê²€ì •ë ¥', 'ê°€ì„¤ê²€ì •']
            tech_level = 'beginner'
            if any(indicator in user_request for indicator in technical_indicators):
                tech_level = 'intermediate'
            
            # ë¶„ì„ ëª©ì  ë¶„ë¥˜
            purpose_indicators = {
                'exploratory': ['íƒìƒ‰', 'ì´í•´', 'íŒŒì•…', 'í™•ì¸'],
                'confirmatory': ['ê²€ì¦', 'ì¦ëª…', 'í…ŒìŠ¤íŠ¸', 'ì…ì¦'],
                'predictive': ['ì˜ˆì¸¡', 'ì˜ˆìƒ', 'ëª¨ë¸ë§', 'ì¶”ì •']
            }
            
            analysis_purpose = 'exploratory'
            for purpose, keywords in purpose_indicators.items():
                if any(keyword in user_request for keyword in keywords):
                    analysis_purpose = purpose
                    break
            
            return {
                'identified_domain': identified_domain,
                'technical_level': tech_level,
                'analysis_purpose': analysis_purpose,
                'user_request_analysis': {
                    'complexity': len(user_request.split()),
                    'specificity': 'high' if len(user_request) > 100 else 'medium'
                },
                'data_context': {
                    'size': data_overview.get('shape', {}).get('rows', 0),
                    'complexity': len(data_overview.get('columns', []))
                }
            }
            
        except Exception as e:
            self.logger.error(f"ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {
                'identified_domain': 'general',
                'technical_level': 'beginner',
                'analysis_purpose': 'exploratory'
            }
    
    def _build_personalized_search_queries(self, input_data: Dict[str, Any],
                                         user_profile: Dict[str, Any]) -> Dict[str, str]:
        """ë§ì¶¤í˜• RAG ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±"""
        domain = user_profile.get('identified_domain', 'general')
        tech_level = user_profile.get('technical_level', 'beginner')
        purpose = user_profile.get('analysis_purpose', 'exploratory')
        user_request = input_data.get('user_request', '')
        
        return {
            'domain_specific': f"""
            ë„ë©”ì¸: {domain}
            ì‚¬ìš©ì ìš”ì²­: {user_request}
            ë¶„ì„ ëª©ì : {purpose}
            ë„ë©”ì¸ ì „ë¬¸ ìš©ì–´, ì¼ë°˜ì ì¸ ë¶„ì„ íŒ¨í„´, ì£¼ì˜ì‚¬í•­, í•´ì„ ê°€ì´ë“œë¼ì¸
            {domain} ë¶„ì•¼ KPI, ì„±ê³¼ ì§€í‘œ, ë¹„ì¦ˆë‹ˆìŠ¤ ë§¥ë½
            """,
            
            'methodological': f"""
            ê¸°ìˆ  ìˆ˜ì¤€: {tech_level}
            ë¶„ì„ ëª©ì : {purpose}
            ë°©ë²•ë¡  ì„ íƒ ê¸°ì¤€, ê°€ì • í™•ì¸ ë°©ë²•, ê²°ê³¼ í•´ì„ ê°€ì´ë“œ
            {tech_level} ìˆ˜ì¤€ ì„¤ëª…, ë‹¨ê³„ë³„ ê°€ì´ë“œ, ì£¼ì˜ì‚¬í•­, ëŒ€ì•ˆ ë°©ë²•
            """,
            
            'implementation': f"""
            ì‚¬ìš©ì ìˆ˜ì¤€: {tech_level}
            êµ¬í˜„ ê°€ì´ë“œ, ì½”ë“œ ì˜ˆì‹œ, ì˜¤ë¥˜ ì²˜ë¦¬, ê²°ê³¼ ê²€ì¦
            ë‹¨ê³„ë³„ ì²´í¬ë¦¬ìŠ¤íŠ¸, í’ˆì§ˆ ê´€ë¦¬, ë¬¸ì œ í•´ê²°
            """,
            
            'risk_management': f"""
            ë¶„ì„ ëª©ì : {purpose}
            ë„ë©”ì¸: {domain}
            ì¼ë°˜ì ì¸ í•¨ì •, í•´ì„ ì˜¤ë¥˜, ì˜ˆë°© ë°©ë²•, ëŒ€ì•ˆ ì „ëµ
            ìœ„í—˜ ìš”ì†Œ, ì™„í™” ë°©ì•ˆ, ê²€ì¦ ë°©ë²•
            """
        }
    
    def _present_agent_recommendations(self, input_data: Dict[str, Any],
                                     rag_context: Dict[str, Any],
                                     conversation_state: Dict[str, Any]) -> Dict[str, Any]:
        """Agentì˜ ì´ˆê¸° ì œì•ˆ ë° ì„¤ëª…"""
        try:
            # RAG ì§€ì‹ì„ í™œìš©í•œ ì„¤ëª… ìƒì„±
            explanation_prompt = self._build_explanation_prompt(
                input_data, rag_context, conversation_state
            )
            
            explanation_response = self.llm_client.generate_response(
                prompt=explanation_prompt,
                temperature=0.3,
                max_tokens=2000,
                system_prompt=self._get_explanation_system_prompt()
            )
            
            # ì‚¬ìš©ì ì¹œí™”ì  í”„ë ˆì  í…Œì´ì…˜ ìƒì„±
            presentation = self._format_user_presentation(
                explanation_response, input_data, rag_context
            )
            
            return presentation
            
        except Exception as e:
            self.logger.error(f"Agent ì¶”ì²œ í”„ë ˆì  í…Œì´ì…˜ ìƒì„± ì˜¤ë¥˜: {e}")
            return self._create_basic_presentation(input_data)
    
    def _collect_user_response(self, presentation: Dict[str, Any],
                             conversation_state: Dict[str, Any],
                             turn_number: int) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì‘ë‹µ ìˆ˜ì§‘"""
        try:
            # í”„ë ˆì  í…Œì´ì…˜ ì¶œë ¥
            self._display_presentation(presentation, turn_number)
            
            # ëŒ€í™”í˜• ì…ë ¥ ìˆ˜ì§‘
            user_input = self._get_interactive_user_input(conversation_state, turn_number)
            
            # ì‘ë‹µ ë¶„ì„ ë° êµ¬ì¡°í™”
            analyzed_response = self._analyze_user_response(user_input, conversation_state)
            
            return analyzed_response
            
        except Exception as e:
            self.logger.error(f"ì‚¬ìš©ì ì‘ë‹µ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return {'response': 'ê¸°ë³¸ ìŠ¹ì¸', 'decision_finalized': True}
    
    def _generate_adaptive_agent_response(self, user_response: Dict[str, Any],
                                        conversation_state: Dict[str, Any],
                                        rag_context: Dict[str, Any],
                                        turn_number: int) -> Dict[str, Any]:
        """Agentì˜ ì ì‘ì  ì‘ë‹µ ìƒì„±"""
        try:
            # ì‚¬ìš©ì ì‘ë‹µ ë¶„ì„
            response_analysis = self._analyze_response_intent(user_response)
            
            # ì ì‘ì  RAG ê²€ìƒ‰
            adaptive_knowledge = self._perform_adaptive_rag_search(
                user_response, response_analysis, rag_context
            )
            
            # ë§ì¶¤í˜• ì‘ë‹µ ìƒì„±
            response_prompt = self._build_adaptive_response_prompt(
                user_response, conversation_state, adaptive_knowledge, turn_number
            )
            
            agent_response = self.llm_client.generate_response(
                prompt=response_prompt,
                temperature=0.4,
                max_tokens=1500,
                system_prompt=self._get_adaptive_response_system_prompt()
            )
            
            # ì‘ë‹µ êµ¬ì¡°í™”
            structured_response = self._structure_agent_response(
                agent_response, user_response, adaptive_knowledge
            )
            
            return structured_response
            
        except Exception as e:
            self.logger.error(f"ì ì‘ì  Agent ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            return self._create_fallback_agent_response(user_response)
    
    def _finalize_analysis_plan(self, conversation_result: Dict[str, Any],
                              input_data: Dict[str, Any],
                              rag_context: Dict[str, Any]) -> Dict[str, Any]:
        """ìµœì¢… ë¶„ì„ ê³„íš í™•ì •"""
        try:
            # ëŒ€í™” ê²°ê³¼ ë¶„ì„
            final_state = conversation_result.get('final_state', {})
            user_preferences = final_state.get('user_preferences', {})
            
            # ì„ íƒëœ ë°©ë²• í™•ì •
            selected_method = user_preferences.get('selected_method') or \
                            input_data.get('agent_analysis_strategy', {}).get('primary_recommendation', {})
            
            # ëŒ€ì•ˆ ë°©ë²• í™•ì •
            confirmed_alternatives = user_preferences.get('alternative_methods', []) or \
                                   input_data.get('agent_analysis_strategy', {}).get('alternative_strategies', [])
            
            # ì‹¤í–‰ íŒŒë¼ë¯¸í„° ì„¤ì •
            execution_parameters = self._derive_execution_parameters(
                conversation_result, rag_context, user_preferences
            )
            
            return {
                'selected_primary_method': selected_method,
                'confirmed_alternatives': confirmed_alternatives,
                'execution_parameters': execution_parameters,
                'user_preferences': user_preferences,
                'finalization_confidence': self._calculate_finalization_confidence(
                    conversation_result, user_preferences
                )
            }
            
        except Exception as e:
            self.logger.error(f"ë¶„ì„ ê³„íš í™•ì • ì˜¤ë¥˜: {e}")
            return self._create_default_analysis_plan(input_data)
    
    def _create_default_rag_context(self) -> Dict[str, Any]:
        """ê¸°ë³¸ RAG ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        return {
            'targeted_domain_knowledge': {'context': '', 'search_results': []},
            'method_specific_guidance': {'context': '', 'search_results': []},
            'user_context_insights': {},
            'risk_mitigation_strategies': [],
            'user_profile': {
                'identified_domain': 'general',
                'technical_level': 'beginner',
                'analysis_purpose': 'exploratory'
            }
        }
    
    def _generate_user_context_insights(self, user_profile: Dict[str, Any],
                                       targeted_domain_knowledge: Dict[str, Any],
                                       method_specific_guidance: Dict[str, Any]) -> Dict[str, Any]:
        """ì‚¬ìš©ì ë§¥ë½ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        try:
            domain = user_profile.get('identified_domain', 'general')
            tech_level = user_profile.get('technical_level', 'beginner')
            purpose = user_profile.get('analysis_purpose', 'exploratory')
            
            return {
                'user_characteristics': {
                    'domain_expertise': domain,
                    'technical_proficiency': tech_level,
                    'analysis_intent': purpose
                },
                'communication_style': {
                    'explanation_depth': 'detailed' if tech_level == 'beginner' else 'concise',
                    'technical_terminology': tech_level != 'beginner',
                    'examples_needed': tech_level == 'beginner'
                },
                'decision_support_needs': {
                    'guidance_level': 'high' if tech_level == 'beginner' else 'medium',
                    'validation_required': True,
                    'alternative_options': tech_level != 'beginner'
                }
            }
            
        except Exception as e:
            self.logger.error(f"ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
            return {}
    
    def _collect_risk_mitigation_strategies(self, input_data: Dict[str, Any],
                                          personalized_queries: Dict[str, str]) -> List[Dict[str, Any]]:
        """ë¦¬ìŠ¤í¬ ì™„í™” ì „ëµ ìˆ˜ì§‘"""
        try:
            risk_strategies = self.rag_manager.search_and_build_context(
                query=personalized_queries['risk_management'],
                collection="statistical_concepts",
                top_k=5,
                context_type="risk_mitigation",
                max_tokens=800
            )
            
            # ê²€ìƒ‰ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ ì „ëµìœ¼ë¡œ ë³€í™˜
            strategies = []
            search_results = risk_strategies.get('search_results', [])
            
            for result in search_results:
                strategy = {
                    'risk_type': self._identify_risk_type(result.get('content', '')),
                    'mitigation_method': result.get('content', '')[:200],
                    'priority': 'high' if result.get('similarity_score', 0) > 0.8 else 'medium',
                    'source': result.get('source', 'unknown')
                }
                strategies.append(strategy)
            
            return strategies
            
        except Exception as e:
            self.logger.error(f"ë¦¬ìŠ¤í¬ ì™„í™” ì „ëµ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return []
    
    def _identify_risk_type(self, content: str) -> str:
        """ì½˜í…ì¸ ì—ì„œ ë¦¬ìŠ¤í¬ ìœ í˜• ì‹ë³„"""
        risk_keywords = {
            'statistical': ['ê°€ì •', 'ì •ê·œì„±', 'ë“±ë¶„ì‚°ì„±', 'ë…ë¦½ì„±'],
            'interpretation': ['í•´ì„', 'ì˜¤í•´', 'í¸í–¥', 'ê²°ë¡ '],
            'implementation': ['êµ¬í˜„', 'ì½”ë“œ', 'ì˜¤ë¥˜', 'ë²„ê·¸'],
            'data_quality': ['ê²°ì¸¡ì¹˜', 'ì´ìƒì¹˜', 'í’ˆì§ˆ', 'ë¬´ê²°ì„±']
        }
        
        content_lower = content.lower()
        for risk_type, keywords in risk_keywords.items():
            if any(keyword in content_lower for keyword in keywords):
                return risk_type
        
        return 'general'
    
    def _initialize_conversation_state(self, input_data: Dict[str, Any],
                                     rag_context: Dict[str, Any]) -> Dict[str, Any]:
        """ëŒ€í™” ì„¸ì…˜ ì´ˆê¸°í™”"""
        return {
            'conversation_id': f"conv_{hash(str(input_data))}"[:12],
            'user_preferences': {},
            'decisions_made': [],
            'questions_raised': [],
            'agent_confidence': 0.5,
            'user_satisfaction': 0.5,
            'context_evolution': [rag_context],
            'decision_criteria': []
        }
    
    def _update_conversation_state(self, current_state: Dict[str, Any],
                                 user_response: Dict[str, Any],
                                 agent_response: Dict[str, Any]) -> Dict[str, Any]:
        """ëŒ€í™” ìƒíƒœ ì—…ë°ì´íŠ¸"""
        updated_state = current_state.copy()
        
        # ì‚¬ìš©ì ì„ í˜¸ë„ ì—…ë°ì´íŠ¸
        if 'preferences' in user_response:
            updated_state['user_preferences'].update(user_response['preferences'])
        
        # ê²°ì •ì‚¬í•­ ì¶”ê°€
        if 'decision' in user_response:
            updated_state['decisions_made'].append(user_response['decision'])
        
        # ì§ˆë¬¸ ì¶”ê°€
        if 'questions' in user_response:
            updated_state['questions_raised'].extend(user_response['questions'])
        
        return updated_state
    
    def _summarize_conversation(self, conversation_turns: List[Dict[str, Any]],
                              initial_presentation: Dict[str, Any],
                              final_state: Dict[str, Any]) -> Dict[str, Any]:
        """ëŒ€í™” ê²°ê³¼ ì¢…í•©"""
        return {
            'total_turns': len(conversation_turns),
            'decisions_made': final_state.get('decisions_made', []),
            'user_preferences': final_state.get('user_preferences', {}),
            'questions_resolved': len(final_state.get('questions_raised', [])),
            'final_confidence': final_state.get('agent_confidence', 0.5),
            'conversation_success': len(final_state.get('decisions_made', [])) > 0
        }
    
    def _create_fallback_conversation_result(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """í´ë°± ëŒ€í™” ê²°ê³¼ ìƒì„±"""
        return {
            'initial_presentation': {'message': 'ê¸°ë³¸ ë¶„ì„ ì œì•ˆ'},
            'conversation_turns': [],
            'conversation_summary': {'conversation_success': False},
            'final_state': {'decisions_made': ['ê¸°ë³¸ ë¶„ì„ ì„ íƒ']}
        }
    
    def _build_explanation_prompt(self, input_data: Dict[str, Any],
                                  rag_context: Dict[str, Any],
                                  conversation_state: Dict[str, Any]) -> str:
        """ì„¤ëª…ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return f"""
ì‚¬ìš©ìì—ê²Œ ë¶„ì„ ë°©ë²•ì„ ì„¤ëª…í•˜ê³  ì„ íƒì„ ë„ì™€ì£¼ì„¸ìš”.

ë°ì´í„°: {input_data.get('data_overview', {})}
ì‚¬ìš©ì ìš”ì²­: {input_data.get('user_request', '')}
ì¶”ì²œ ë°©ë²•: {input_data.get('agent_analysis_strategy', {})}

ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
        """
    
    def _get_explanation_system_prompt(self) -> str:
        """ì„¤ëª…ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"""
        return "ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë°ì´í„° ë¶„ì„ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."
    
    def _format_user_presentation(self, explanation_response: str,
                                  input_data: Dict[str, Any],
                                  rag_context: Dict[str, Any]) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì¹œí™”ì  í”„ë ˆì  í…Œì´ì…˜ í˜•ì‹í™”"""
        return {
            'explanation': explanation_response,
            'options': ['ê¸°ë³¸ ë¶„ì„ ìŠ¹ì¸', 'ëŒ€ì•ˆ ë°©ë²• ìš”ì²­', 'ìˆ˜ì • ìš”ì²­'],
            'recommendation': 'ê¸°ë³¸ ë¶„ì„ì„ ì¶”ì²œí•©ë‹ˆë‹¤'
        }
    
    def _create_basic_presentation(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ê¸°ë³¸ í”„ë ˆì  í…Œì´ì…˜ ìƒì„±"""
        return {
            'explanation': 'ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ ê¸°ë³¸ ë°©ë²•ì„ ì œì•ˆë“œë¦½ë‹ˆë‹¤.',
            'options': ['ìŠ¹ì¸', 'ê±°ë¶€'],
            'recommendation': 'ê¸°ë³¸ ë¶„ì„ ë°©ë²•'
        }
    
    def _display_presentation(self, presentation: Dict[str, Any], turn_number: int):
        """í”„ë ˆì  í…Œì´ì…˜ ì¶œë ¥"""
        print(f"\n=== ë¶„ì„ ë°©ë²• ì œì•ˆ (í„´ {turn_number}) ===")
        print(presentation.get('explanation', ''))
        print("\nì˜µì…˜:")
        for i, option in enumerate(presentation.get('options', []), 1):
            print(f"{i}. {option}")
    
    def _get_interactive_user_input(self, conversation_state: Dict[str, Any],
                                  turn_number: int) -> str:
        """ëŒ€í™”í˜• ì‚¬ìš©ì ì…ë ¥ ìˆ˜ì§‘"""
        # ë¹„ëŒ€í™”í˜• ëª¨ë“œì—ì„œëŠ” ê¸°ë³¸ê°’ ë°˜í™˜
        return "1"  # ì²« ë²ˆì§¸ ì˜µì…˜ ì„ íƒ
    
    def _analyze_user_response(self, user_input: str,
                             conversation_state: Dict[str, Any]) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì‘ë‹µ ë¶„ì„"""
        return {
            'response': user_input,
            'decision_finalized': True,
            'preferences': {'selected_method': 'default'}
        }
    
    def _analyze_response_intent(self, user_response: Dict[str, Any]) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì‘ë‹µ ì˜ë„ ë¶„ì„"""
        return {
            'intent': 'approval',
            'confidence': 0.8,
            'needs_clarification': False
        }
    
    def _perform_adaptive_rag_search(self, user_response: Dict[str, Any],
                                   response_analysis: Dict[str, Any],
                                   rag_context: Dict[str, Any]) -> Dict[str, Any]:
        """ì ì‘ì  RAG ê²€ìƒ‰"""
        return {'additional_context': 'ì¶”ê°€ ì •ë³´ ì—†ìŒ'}
    
    def _build_adaptive_response_prompt(self, user_response: Dict[str, Any],
                                      conversation_state: Dict[str, Any],
                                      adaptive_knowledge: Dict[str, Any],
                                      turn_number: int) -> str:
        """ì ì‘ì  ì‘ë‹µ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return f"ì‚¬ìš©ì ì‘ë‹µì— ëŒ€í•œ ì ì‘ì  ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”. í„´: {turn_number}"
    
    def _get_adaptive_response_system_prompt(self) -> str:
        """ì ì‘ì  ì‘ë‹µìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"""
        return "ì‚¬ìš©ìì˜ ì˜ê²¬ì„ ê³ ë ¤í•˜ì—¬ ì ì ˆí•œ ë¶„ì„ ë°©ë²•ì„ ì œì•ˆí•´ì£¼ì„¸ìš”."
    
    def _structure_agent_response(self, agent_response: str,
                                user_response: Dict[str, Any],
                                adaptive_knowledge: Dict[str, Any]) -> Dict[str, Any]:
        """Agent ì‘ë‹µ êµ¬ì¡°í™”"""
        return {
            'message': agent_response,
            'suggestions': ['ì¶”ê°€ ê²€í† '],
            'confidence': 0.7
        }
    
    def _create_fallback_agent_response(self, user_response: Dict[str, Any]) -> Dict[str, Any]:
        """í´ë°± Agent ì‘ë‹µ"""
        return {
            'message': 'ê¸°ë³¸ ë¶„ì„ ë°©ë²•ì„ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.',
            'suggestions': [],
            'confidence': 0.5
        }
    
    def _derive_execution_parameters(self, conversation_result: Dict[str, Any],
                                   rag_context: Dict[str, Any],
                                   user_preferences: Dict[str, Any]) -> Dict[str, Any]:
        """ì‹¤í–‰ íŒŒë¼ë¯¸í„° ë„ì¶œ"""
        return {
            'method': user_preferences.get('selected_method', 'default'),
            'confidence_level': 0.95,
            'output_format': 'standard'
        }
    
    def _calculate_finalization_confidence(self, conversation_result: Dict[str, Any],
                                         user_preferences: Dict[str, Any]) -> float:
        """í™•ì • ì‹ ë¢°ë„ ê³„ì‚°"""
        return 0.8
    
    def _create_default_analysis_plan(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ê¸°ë³¸ ë¶„ì„ ê³„íš ìƒì„±"""
        return {
            'selected_primary_method': {'method': 'default_analysis'},
            'confirmed_alternatives': [],
            'execution_parameters': {'confidence_level': 0.95},
            'user_preferences': {'selected_method': 'default'},
            'finalization_confidence': 0.5
        }
    
    def _generate_adaptive_adjustments(self, finalized_analysis_plan: Dict[str, Any],
                                     rag_context: Dict[str, Any],
                                     conversation_result: Dict[str, Any]) -> Dict[str, Any]:
        """ì ì‘í˜• ì‹¤í–‰ ì¡°ì •ì‚¬í•­ ìƒì„±"""
        return {
            'customized_parameters': {},
            'dynamic_checkpoints': [],
            'quality_assurance_plan': {},
            'contingency_protocols': {}
        }
    
    def _document_decision_process(self, conversation_result: Dict[str, Any],
                                 finalized_analysis_plan: Dict[str, Any],
                                 input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì˜ì‚¬ê²°ì • ê³¼ì • ë¬¸ì„œí™”"""
        return {
            'conversation_summary': conversation_result.get('conversation_summary', {}),
            'decision_rationale': {'reason': 'ì‚¬ìš©ì ìŠ¹ì¸'},
            'agent_recommendations': {'primary': 'ê¸°ë³¸ ë¶„ì„'},
            'user_feedback_integration': {'feedback': 'ê¸ì •ì '}
        }
    
    def _generate_knowledge_insights(self, finalized_analysis_plan: Dict[str, Any],
                                   rag_context: Dict[str, Any],
                                   conversation_result: Dict[str, Any]) -> Dict[str, Any]:
        """ì§€ì‹ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        return {
            'domain_specific_considerations': [],
            'methodological_best_practices': [],
            'implementation_guidance': {},
            'expected_outcomes': {}
        }


