{
  "automated_preprocessing": {
    "system_prompt": "당신은 통계 분석을 위한 자동화된 데이터 전처리 코드를 생성하는 전문가입니다. workflow_graph.json의 automated_preprocessing 단계를 수행하며, SafeCodeExecutor에서 안전하게 실행 가능한 코드를 생성합니다.",
    "user_prompt_template": "**자동 데이터 전처리 코드 생성** (workflow_node: automated_preprocessing)\n\n**선택된 분석 방법:** {selected_method}\n**데이터 정보:**\n- 데이터프레임명: {dataframe_name}\n- 대상 변수: {target_variables}\n- 데이터 타입: {column_types}\n- 결측치 정보: {missing_info}\n\n**전처리 요구사항:**\n1. 선택된 분석 방법에 필요한 변수 자동 식별\n2. 데이터 타입 자동 변환 (필요시)\n3. 결측치 처리 (임계값 기준 자동 처리)\n4. 명백한 이상치 자동 식별 및 처리\n5. SafeCodeExecutor 호환 코드 생성\n\n**안전성 요구사항:**\n- pandas, numpy, scipy만 사용\n- 파일 시스템 접근 금지\n- 외부 네트워크 접근 금지\n- 메모리 효율적 처리\n\n**응답 형식:**\n```json\n{\n  \"preprocessing_plan\": {\n    \"steps\": [\n      {\n        \"step_name\": \"단계명\",\n        \"description\": \"상세 설명\",\n        \"rationale\": \"필요성\"\n      }\n    ],\n    \"estimated_execution_time\": \"예상 실행 시간\"\n  },\n  \"preprocessing_code\": {\n    \"imports\": [\n      \"import pandas as pd\",\n      \"import numpy as np\",\n      \"from scipy import stats\"\n    ],\n    \"main_code\": \"def preprocess_data(df):\\n    preprocessing_log = []\\n    target_vars = {target_variables}\\n    preprocessing_log.append('변수 식별 완료')\\n    return {'processed_data': df_processed, 'preprocessing_log': preprocessing_log, 'data_quality_report': data_quality_report}\\n\\nresult = preprocess_data({dataframe_name})\\ndf_processed = result['processed_data']\\npreprocessing_log = result['preprocessing_log']\\ndata_quality_report = result['data_quality_report']\",\n    \"validation_code\": \"def validate_preprocessing(original_df, processed_df):\\n    validation_report = {'original_shape': original_df.shape, 'processed_shape': processed_df.shape, 'data_loss_percentage': 0.0, 'quality_checks': []}\\n    return validation_report\\n\\nvalidation_result = validate_preprocessing({dataframe_name}, df_processed)\"\n  },\n  \"error_handling\": [\n    {\n      \"error_type\": \"데이터 타입 변환 실패\",\n      \"handling_strategy\": \"원본 유지 및 경고 로그\",\n      \"fallback_code\": \"# 타입 변환 실패시 대안 코드\"\n    }\n  ]\n}\n```",
    "preprocessing_strategies": {
      "missing_data": {
        "numerical": ["mean_imputation", "median_imputation", "forward_fill"],
        "categorical": ["mode_imputation", "new_category"]
      },
      "outlier_detection": ["z_score", "iqr_method", "isolation_forest"],
      "data_transformation": ["log_transform", "sqrt_transform", "standardization"]
    }
  },

  "automated_assumption_testing": {
    "system_prompt": "당신은 통계적 가정을 자동으로 검정하는 코드를 생성하는 전문가입니다. workflow_graph.json의 automated_assumption_testing 단계를 수행하며, 각 통계 방법의 전제조건을 체계적으로 확인합니다.",
    "user_prompt_template": "**통계적 가정 자동 검정 코드 생성** (workflow_node: automated_assumption_testing)\n\n**선택된 통계 방법:** {statistical_method}\n**데이터 변수:**\n- 종속변수: {dependent_variables}\n- 독립변수: {independent_variables}\n- 그룹화 변수: {grouping_variables}\n\n**필요한 가정 검정:**\n{required_assumptions}\n\n**검정 요구사항:**\n1. 정규성 검정 (Shapiro-Wilk, Kolmogorov-Smirnov)\n2. 등분산성 검정 (Levene's test, Bartlett's test)\n3. 독립성 검정 (필요시)\n4. 표본 크기 적절성 확인\n5. 가정 위반 시 자동 대안 방법 선택\n\n**응답 형식:**\n```json\n{\n  \"assumption_testing_plan\": {\n    \"required_tests\": [\n      {\n        \"test_name\": \"검정명\",\n        \"purpose\": \"검정 목적\",\n        \"null_hypothesis\": \"귀무가설\",\n        \"alternative_hypothesis\": \"대립가설\",\n        \"significance_level\": 0.05\n      }\n    ]\n  },\n  \"assumption_testing_code\": {\n    \"imports\": [\n      \"import pandas as pd\",\n      \"import numpy as np\",\n      \"from scipy import stats\",\n      \"from scipy.stats import shapiro, levene, bartlett, kstest\"\n    ],\n    \"main_code\": \"def test_statistical_assumptions(df, dependent_var, independent_vars=None, grouping_var=None):\\n    assumption_results = {'normality': {}, 'homogeneity': {}, 'independence': {}, 'sample_size': {}, 'overall_assessment': {}, 'recommendations': []}\\n    if grouping_var:\\n        groups = df[grouping_var].unique()\\n        for group in groups:\\n            group_data = df[df[grouping_var] == group][dependent_var].dropna()\\n            if len(group_data) < 5000:\\n                stat, p_value = shapiro(group_data)\\n                assumption_results['normality'][f'{group}_shapiro'] = {'statistic': stat, 'p_value': p_value, 'is_normal': p_value > 0.05}\\n    return assumption_results\\n\\nassumption_results = test_statistical_assumptions(df, '{dependent_variables}', grouping_var='{grouping_variables}')\",\n    \"alternative_methods\": {\n      \"normality_violation\": {\n        \"anova_alternative\": \"kruskal_wallis\",\n        \"ttest_alternative\": \"mann_whitney\"\n      },\n      \"homogeneity_violation\": {\n        \"welch_anova\": \"불등분산 허용 ANOVA\",\n        \"brown_forsythe\": \"로버스트 등분산성 검정\"\n      }\n    }\n  }\n}\n```",
    "assumption_tests": {
      "normality": {
        "shapiro_wilk": "n < 5000, 가장 강력한 검정",
        "kolmogorov_smirnov": "n >= 5000, 대표본용",
        "anderson_darling": "중간 크기 표본, 민감도 높음"
      },
      "homogeneity": {
        "levene": "로버스트, 분포 가정 완화",
        "bartlett": "정규성 가정하에서 강력",
        "brown_forsythe": "이상치에 덜 민감"
      }
    }
  },

  "statistical_analysis_execution": {
    "system_prompt": "당신은 확정된 통계 방법으로 최종 분석을 수행하는 코드를 생성하는 전문가입니다. workflow_graph.json의 statistical_analysis_execution 단계를 수행하며, 완전한 통계 분석 결과를 생성합니다.",
    "user_prompt_template": "**통계 분석 실행 코드 생성** (workflow_node: statistical_analysis_execution)\n\n**확정된 분석 방법:** {confirmed_method}\n**전처리된 데이터:** {preprocessed_data_info}\n**가정 검정 결과:** {assumption_results}\n\n**분석 실행 요구사항:**\n1. 확정된 통계 방법으로 분석 실행\n2. 효과 크기 계산 (Cohen's d, eta-squared 등)\n3. 신뢰구간 계산\n4. 사후 검정 수행 (필요시)\n5. 결과 시각화 생성\n6. 비즈니스 해석을 위한 구조화된 결과\n\n**출력 요구사항:**\n- 통계량과 p-value\n- 효과 크기와 해석\n- 신뢰구간\n- 시각화 차트\n- 비즈니스 관점 해석 가이드\n\n**응답 형식:**\n```json\n{\n  \"analysis_execution_plan\": {\n    \"method_details\": {\n      \"primary_method\": \"{confirmed_method}\",\n      \"post_hoc_tests\": [],\n      \"effect_size_measures\": [],\n      \"visualization_types\": []\n    }\n  },\n  \"analysis_code\": {\n    \"imports\": [\n      \"import pandas as pd\",\n      \"import numpy as np\",\n      \"from scipy import stats\",\n      \"import matplotlib.pyplot as plt\",\n      \"import seaborn as sns\"\n    ],\n    \"main_analysis\": \"def execute_statistical_analysis(df, method='{confirmed_method}'):\\n    results = {'statistics': {}, 'effect_size': {}, 'confidence_intervals': {}, 'post_hoc': {}, 'visualizations': {}}\\n    # 주 분석 실행\\n    if method == 'anova':\\n        from scipy.stats import f_oneway\\n        groups = [df[df['group'] == g]['value'].values for g in df['group'].unique()]\\n        f_stat, p_value = f_oneway(*groups)\\n        results['statistics'] = {'f_statistic': f_stat, 'p_value': p_value}\\n    return results\\n\\nanalysis_results = execute_statistical_analysis(df_processed)\",\n    \"effect_size_calculation\": \"def calculate_effect_size(results, method):\\n    if method == 'anova':\\n        # Eta-squared 계산\\n        eta_squared = results['statistics']['f_statistic'] / (results['statistics']['f_statistic'] + results['statistics']['df_error'])\\n        return {'eta_squared': eta_squared, 'interpretation': 'small' if eta_squared < 0.06 else 'medium' if eta_squared < 0.14 else 'large'}\\n    return {}\\n\\neffect_size = calculate_effect_size(analysis_results, '{confirmed_method}')\",\n    \"visualization_code\": \"def create_visualizations(df, results):\\n    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\\n    # 박스플롯\\n    sns.boxplot(data=df, x='group', y='value', ax=axes[0,0])\\n    axes[0,0].set_title('그룹별 분포 비교')\\n    # 바이올린 플롯\\n    sns.violinplot(data=df, x='group', y='value', ax=axes[0,1])\\n    axes[0,1].set_title('그룹별 분포 상세')\\n    plt.tight_layout()\\n    return fig\\n\\nvisualization = create_visualizations(df_processed, analysis_results)\"\n  },\n  \"business_interpretation\": {\n    \"result_summary\": \"통계적 유의성과 실무적 의미 요약\",\n    \"effect_magnitude\": \"효과 크기의 비즈니스적 해석\",\n    \"actionable_insights\": \"실행 가능한 비즈니스 인사이트\",\n    \"limitations\": \"분석 결과의 한계점\",\n    \"recommendations\": \"후속 조치 권장사항\"\n  }\n}\n```",
    "statistical_methods": {
      "parametric": {
        "t_test": "두 그룹 평균 비교",
        "anova": "다중 그룹 평균 비교", 
        "regression": "예측 및 관계 분석"
      },
      "non_parametric": {
        "mann_whitney": "두 그룹 중위수 비교",
        "kruskal_wallis": "다중 그룹 중위수 비교",
        "spearman": "순위 상관관계"
      }
    }
  }
} 