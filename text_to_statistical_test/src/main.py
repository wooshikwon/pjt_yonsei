import typer
import pandas as pd
from pathlib import Path
from datetime import datetime
import sys
import os
from dotenv import load_dotenv

# í†µí•©ëœ ê²½ê³  ë° ë¡œê¹… ì„¤ì •
from src.utils.warnings_config import setup_warnings_and_logging
setup_warnings_and_logging()

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

from src.components.context import Context
from src.components.rag_retriever import RAGRetriever
from src.components.code_executor import CodeExecutor
from src.agent import Agent
from src.utils.logger import get_logger

app = typer.Typer()

@app.command()
def analyze(
    file_name: str = typer.Option(..., "--file", help="Name of the data file in 'input_data/data_files/'"),
    request: str = typer.Option(..., "--request", help="Your natural language request for analysis.")
):
    """
    ë°ì´í„° íŒŒì¼ê³¼ ì‚¬ìš©ì ìš”ì²­ì„ ê¸°ë°˜ìœ¼ë¡œ ì „ì²´ í†µê³„ ë¶„ì„ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    # ë¡œê±° ì´ˆê¸°í™”
    logger = get_logger()
    
    # --- ì´ˆê¸°í™” ---
    logger.log_system_info("ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
    
    # .env íŒŒì¼ ë‹¤ì‹œ ë¡œë“œ (ì‹¤ì‹œê°„ ë³€ê²½ì‚¬í•­ ë°˜ì˜)
    load_dotenv(override=True)
    
    # í™˜ê²½ë³€ìˆ˜ ì½ê¸°
    use_rag = os.getenv("USE_RAG", "True").lower() == "true"
    rebuild_vector_store = os.getenv("REBUILD_VECTOR_STORE", "False").lower() == "true"
    


    # ê²½ë¡œ ì„¤ì •
    base_path = Path.cwd()
    input_file_path = base_path / "input_data/data_files" / file_name
    knowledge_base_path = str(base_path / "resources/knowledge_base")
    vector_store_path = str(base_path / "resources/rag_index")
    report_path = base_path / "output_data/reports"
    report_path.mkdir(parents=True, exist_ok=True)

    # ì»´í¬ë„ŒíŠ¸ ì¸ìŠ¤í„´ìŠ¤í™”
    context = Context()
    agent = Agent()
    executor = CodeExecutor()

    context.set_user_input(file_path=str(input_file_path), request=request)
    logger.log_detailed(f"User Request: {request}")
    logger.log_detailed(f"Data File: {input_file_path}")

    # --- Step 0: ë²¡í„° ìŠ¤í† ì–´ ê´€ë¦¬ (ë…ë¦½ì  ì‹¤í–‰) ---
    if rebuild_vector_store:
        logger.log_step_start(0, "ë²¡í„° ìŠ¤í† ì–´ ì¬êµ¬ì¶•")
        try:
            # ì„ì‹œ RAGRetriever ì¸ìŠ¤í„´ìŠ¤ë¡œ ì¸ë±ìŠ¤ ì¬êµ¬ì¶•ë§Œ ìˆ˜í–‰
            temp_retriever = RAGRetriever(
                knowledge_base_path=knowledge_base_path,
                vector_store_path=vector_store_path,
                rebuild=True
            )
            temp_retriever.load()  # rebuild=Trueì´ë¯€ë¡œ ê¸°ì¡´ ì‚­ì œ í›„ ì¬êµ¬ì¶•
            logger.log_step_success(0, "ë²¡í„° ìŠ¤í† ì–´ ì¬êµ¬ì¶• ì™„ë£Œ")
        except Exception as e:
            logger.log_step_failure(0, f"ë²¡í„° ìŠ¤í† ì–´ ì¬êµ¬ì¶• ì‹¤íŒ¨: {str(e)}")
            logger.log_detailed(f"Vector store rebuild error: {e}", "ERROR")

    # --- Step 1: RAGë¡œ ì»¨í…ìŠ¤íŠ¸ ê°•í™” (ì¡°ê±´ë¶€ ì‹¤í–‰) ---
    if use_rag:
        logger.log_step_start(1, "RAG ì»¨í…ìŠ¤íŠ¸ ê°•í™”")
        
        # ì¸ë±ìŠ¤ ì¡´ì¬ ì—¬ë¶€ ë¨¼ì € í™•ì¸
        vector_store_path_obj = Path(vector_store_path)
        if not (vector_store_path_obj / "docstore.json").exists():
            logger.log_step_failure(1, "ë²¡í„° ì¸ë±ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            print("\nâš ï¸  RAG ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
            print("ğŸ“‹ í•´ê²° ë°©ë²•: .env íŒŒì¼ì—ì„œ REBUILD_VECTOR_STORE=Trueë¡œ ì„¤ì •í•˜ê³  ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            print(f"ğŸ“ ì§€ì‹ ë² ì´ìŠ¤ ê²½ë¡œ: {knowledge_base_path}")
            print(f"ğŸ“ ë²¡í„° ìŠ¤í† ì–´ ê²½ë¡œ: {vector_store_path}")
            print("\nğŸ’¡ ì§€ì‹ ë² ì´ìŠ¤ì— .md íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ë²¡í„° ìŠ¤í† ì–´ë¥¼ ë¹Œë“œí•´ì£¼ì„¸ìš”.\n")
            # RAG ì—†ì´ ê³„ì† ì§„í–‰
            logger.log_step_success(1, "RAG ì¸ë±ìŠ¤ ì—†ìŒ - RAG ì—†ì´ ë¶„ì„ ì§„í–‰")
        else:
            retriever = RAGRetriever(
                knowledge_base_path=knowledge_base_path, 
                vector_store_path=vector_store_path,
                rebuild=False  # ì¬êµ¬ì¶•ì€ Step 0ì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë¨
            )
            try:
                retriever.load()
                rag_context = retriever.retrieve_context(request)
                context.add_rag_result(rag_context)
                logger.log_rag_context(rag_context)
                logger.log_step_success(1, "ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰ ì™„ë£Œ")
            except Exception as e:
                logger.log_step_failure(1, str(e))
                logger.log_detailed(f"RAG Error: {e}", "ERROR")
    else:
        logger.log_step_start(1, "RAG ê±´ë„ˆë›°ê¸°")
        logger.log_step_success(1, "í™˜ê²½ ì„¤ì •ì— ë”°ë¼ RAG ë‹¨ê³„ ìƒëµ")

    # --- Step 2: ë°ì´í„° ë¡œë”© ë° ì´ˆê¸° íƒìƒ‰ ---
    logger.log_step_start(2, "ë°ì´í„° ë¡œë”© ë° íƒìƒ‰")
    try:
        if input_file_path.suffix == '.csv':
            df = pd.read_csv(input_file_path)
        elif input_file_path.suffix in ['.xlsx', '.xls']:
            df = pd.read_excel(input_file_path)
        elif input_file_path.suffix == '.parquet':
            df = pd.read_parquet(input_file_path)
        else:
            raise ValueError(f"Unsupported file type: {input_file_path.suffix}")
        
        logger.log_detailed(f"Data shape: {df.shape}")
        logger.log_detailed(f"Columns: {list(df.columns)}")
        logger.log_step_success(2, f"ë°ì´í„° ë¡œë”© ì™„ë£Œ ({df.shape[0]}í–‰, {df.shape[1]}ì—´)")
    except FileNotFoundError:
        error_msg = f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_file_path}"
        logger.log_step_failure(2, error_msg)
        logger.log_detailed(error_msg, "ERROR")
        sys.exit(1)
    except Exception as e:
        error_msg = f"ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
        logger.log_step_failure(2, error_msg)
        logger.log_detailed(error_msg, "ERROR")
        sys.exit(1)

    # --- Step 3: í†µê³„ ë¶„ì„ ê³„íš ìˆ˜ë¦½ ---
    logger.log_step_start(3, "ë¶„ì„ ê³„íš ìˆ˜ë¦½")
    try:
        schema = {col: str(dtype) for col, dtype in df.dtypes.to_dict().items()}
        null_values = df.isnull().sum().to_dict()
        sample_data = df.head().to_string()
        context.set_data_info(schema=schema, null_values=null_values, sample_data=sample_data)

        plan = agent.generate_analysis_plan(context)
        context.set_analysis_plan(plan)
        
        logger.log_detailed("Generated Analysis Plan:")
        for i, step in enumerate(plan, 1):
            logger.log_detailed(f"{i}. {step}")
        
        logger.log_step_success(3, f"ë¶„ì„ ê³„íš ìˆ˜ë¦½ ì™„ë£Œ ({len(plan)}ë‹¨ê³„)")
    except Exception as e:
        logger.log_step_failure(3, str(e))
        logger.log_detailed(f"Analysis planning error: {e}", "ERROR")
        sys.exit(1)
    
    # --- Step 4: ê³„íš ê¸°ë°˜ ì‹¤í–‰ ë° ìê°€ ìˆ˜ì • ë£¨í”„ ---
    logger.log_step_start(4, "ë¶„ì„ ê³„íš ì‹¤í–‰")
    try:
        failed_steps = 0
        for i, step in enumerate(context.analysis_plan):
            step_num = i + 1
            logger.log_detailed(f"\nExecuting Step {step_num}: {step}")
            
            code = agent.generate_code_for_step(context, step)
            logger.log_generated_code(step_num, code)

            result, success = executor.run(code, global_vars={'df': df})
            logger.log_execution_result(step_num, result, success)
            
            if success:
                context.add_to_history({'role': 'assistant', 'code': code})
                context.add_to_history({'role': 'system', 'result': result})
            else:
                logger.log_detailed(f"Step {step_num} failed, attempting self-correction...")
                context.add_to_history({'role': 'assistant', 'code': code})
                context.add_to_history({'role': 'system', 'error': result})
                
                corrected_code = agent.self_correct_code(context, step, code, result)
                logger.log_detailed(f"Corrected code generated for step {step_num}")
                
                result, success = executor.run(corrected_code, global_vars={'df': df})
                logger.log_execution_result(step_num, f"CORRECTED: {result}", success)
                
                if success:
                    context.add_to_history({'role': 'assistant', 'code': corrected_code})
                    context.add_to_history({'role': 'system', 'result': result})
                else:
                    failed_steps += 1
                    logger.log_detailed(f"FATAL: Self-correction failed for step {step_num}")
        
        if failed_steps == 0:
            logger.log_step_success(4, f"ëª¨ë“  ë¶„ì„ ë‹¨ê³„ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ")
        else:
            logger.log_step_success(4, f"ë¶„ì„ ì™„ë£Œ (ì¼ë¶€ ë‹¨ê³„ ì‹¤íŒ¨: {failed_steps}ê°œ)")
            
    except Exception as e:
        logger.log_step_failure(4, str(e))
        logger.log_detailed(f"Analysis execution error: {e}", "ERROR")
        sys.exit(1)
    
    # --- Step 5: ìµœì¢… ë³´ê³ ì„œ ìƒì„± ---
    logger.log_step_start(5, "ìµœì¢… ë³´ê³ ì„œ ìƒì„±")
    try:
        final_report = agent.generate_final_report(context)
        context.set_final_report(final_report)
        logger.log_step_success(5, "ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
    except Exception as e:
        logger.log_step_failure(5, str(e))
        logger.log_detailed(f"Report generation error: {e}", "ERROR")
        final_report = "ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    # --- ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥ ---
    logger.print_final_report(final_report)
    
    timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
    report_file_name = f"report-{timestamp}.md"
    report_file_path = report_path / report_file_name
    
    try:
        with open(report_file_path, 'w', encoding='utf-8') as f:
            f.write(final_report)
        logger.log_report_saved(str(report_file_path))
    except Exception as e:
        logger.log_detailed(f"Failed to save report: {e}", "ERROR")

if __name__ == "__main__":
    app() 