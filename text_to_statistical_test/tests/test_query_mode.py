#!/usr/bin/env python3
"""
ê°œì„ ëœ ìì—°ì–´ ìš”ì²­ ëª¨ë“œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ëª¨í˜¸í•œ ìš”ì²­ ì²˜ë¦¬ ë° ë‹¤ì¤‘ í›„ë³´ ì œì‹œ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import sys
import os
import pandas as pd
import json
from datetime import datetime
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€ (ìƒìœ„ ë””ë ‰í† ë¦¬)
sys.path.insert(0, str(Path(__file__).parent.parent))

class MockLLMClient:
    """API í‚¤ ì—†ì´ë„ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•œ Mock LLM í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self):
        self.call_count = 0
        
    def generate_text(self, prompt: str) -> str:
        """Mock LLM ì‘ë‹µ ìƒì„±"""
        self.call_count += 1
        
        # 1-1 ë‹¨ê³„: ì‚¬ìš©ì ìš”ì²­ ë¶„ì„
        if "ì‚¬ìš©ì ìš”ì²­ ë¶„ì„" in prompt and "ê·¸ë£¹ë³„ í‰ê·  ì°¨ì´" in prompt:
            return self._generate_analysis_candidates_response()
        
        # 1-2 ë‹¨ê³„: ë¶„ì„ ëª©í‘œ í™•ì¸
        elif "ë¶„ì„ ëª©í‘œ í™•ì¸" in prompt and "analysis_candidates" in prompt:
            return self._generate_confirmation_response()
        
        # 2-1 ë‹¨ê³„: ë°ì´í„° ë¡œë”©
        elif "ë°ì´í„° ë¡œë”©" in prompt:
            return self._generate_data_loading_response()
        
        # 2-2 ë‹¨ê³„: ë³€ìˆ˜ íƒ€ì… ì‹ë³„
        elif "ë³€ìˆ˜ íƒ€ì… ì‹ë³„" in prompt:
            return self._generate_variable_type_response()
        
        # ê¸°ë³¸ ì‘ë‹µ
        else:
            return f"""
            ```json
            {{
                "action": "ì²˜ë¦¬ë¨",
                "content": "Mock ì‘ë‹µ {self.call_count}",
                "confidence": 0.8,
                "reasoning": "í…ŒìŠ¤íŠ¸ ì‘ë‹µì…ë‹ˆë‹¤"
            }}
            ```
            """
    
    def _generate_analysis_candidates_response(self) -> str:
        """1-1 ë‹¨ê³„: ëª¨í˜¸í•œ "ê·¸ë£¹ë³„ í‰ê·  ì°¨ì´" ìš”ì²­ì— ëŒ€í•œ ë‹¤ì¤‘ í•´ì„"""
        return """
        ## ì‚¬ìš©ì ìš”ì²­ ë¶„ì„ ê²°ê³¼

        "ê·¸ë£¹ë³„ í‰ê·  ì°¨ì´ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”"ë¼ëŠ” ìš”ì²­ì„ ë‹¤ìŒê³¼ ê°™ì´ í•´ì„í–ˆìŠµë‹ˆë‹¤:

        ```json
        {
            "action": "ë¶„ì„",
            "content": "ì‚¬ìš©ì ìš”ì²­ì— ëŒ€í•œ ë‹¤ì¤‘ í•´ì„ ê²°ê³¼ë¥¼ ì œì‹œí•©ë‹ˆë‹¤",
            "interpretation_summary": "ê·¸ë£¹ ë³€ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì—°ì†í˜• ê²°ê³¼ ë³€ìˆ˜ì˜ í‰ê· ê°’ì„ ë¹„êµí•˜ëŠ” ë¶„ì„ìœ¼ë¡œ í•´ì„ë©ë‹ˆë‹¤",
            "analysis_candidates": [
                {
                    "priority": 1,
                    "analysis_goal": "ê·¸ë£¹ë³„ ì ìˆ˜ í‰ê·  ë¹„êµ ë¶„ì„",
                    "analysis_type": "One-way ANOVA",
                    "dependent_variable": "ì ìˆ˜",
                    "independent_variable": "ê·¸ë£¹",
                    "hypothesis": "ê·€ë¬´ê°€ì„¤: ëª¨ë“  ê·¸ë£¹ì˜ ì ìˆ˜ í‰ê· ì´ ê°™ë‹¤ vs ëŒ€ë¦½ê°€ì„¤: ì ì–´ë„ í•˜ë‚˜ì˜ ê·¸ë£¹ í‰ê· ì´ ë‹¤ë¥´ë‹¤",
                    "reasoning": "ë°ì´í„°ì— 3ê°œ ê·¸ë£¹(A, B, C)ê³¼ ì—°ì†í˜• ì ìˆ˜ ë³€ìˆ˜ê°€ ìˆì–´ ë¶„ì‚°ë¶„ì„ì´ ê°€ì¥ ì í•©",
                    "confidence": 0.85
                },
                {
                    "priority": 2,
                    "analysis_goal": "ê·¸ë£¹ë³„ ë§Œì¡±ë„ í‰ê·  ë¹„êµ ë¶„ì„",
                    "analysis_type": "Kruskal-Wallis Test",
                    "dependent_variable": "ë§Œì¡±ë„",
                    "independent_variable": "ê·¸ë£¹",
                    "hypothesis": "ê·€ë¬´ê°€ì„¤: ëª¨ë“  ê·¸ë£¹ì˜ ë§Œì¡±ë„ ë¶„í¬ê°€ ê°™ë‹¤ vs ëŒ€ë¦½ê°€ì„¤: ì ì–´ë„ í•˜ë‚˜ì˜ ê·¸ë£¹ ë¶„í¬ê°€ ë‹¤ë¥´ë‹¤",
                    "reasoning": "ë§Œì¡±ë„ëŠ” ì„œì—´ ì²™ë„ë¡œ ë³´ì´ë¯€ë¡œ ë¹„ëª¨ìˆ˜ ê²€ì •ë„ ê³ ë ¤í•  ìˆ˜ ìˆìŒ",
                    "confidence": 0.65
                },
                {
                    "priority": 3,
                    "analysis_goal": "ê·¸ë£¹ë³„ ë‹¤ì¤‘ ë³€ìˆ˜ í‰ê·  ë¹„êµ",
                    "analysis_type": "MANOVA",
                    "dependent_variable": "ì ìˆ˜, ë§Œì¡±ë„, ê²½í—˜ë…„ìˆ˜",
                    "independent_variable": "ê·¸ë£¹",
                    "hypothesis": "ë‹¤ë³€ëŸ‰ í‰ê·  ë²¡í„°ê°€ ê·¸ë£¹ ê°„ ë‹¤ë¥´ë‹¤",
                    "reasoning": "ì—¬ëŸ¬ ì¢…ì†ë³€ìˆ˜ë¥¼ ë™ì‹œì— ê³ ë ¤í•œ ì¢…í•©ì  ë¶„ì„",
                    "confidence": 0.45
                }
            ],
            "uncertainty_areas": [
                "ì •í™•íˆ ì–´ë–¤ ë³€ìˆ˜ì˜ í‰ê· ì„ ë¹„êµí•˜ê³  ì‹¶ì€ì§€ ëª…ì‹œë˜ì§€ ì•ŠìŒ",
                "ê·¸ë£¹ ê°„ ë‹¨ìˆœ ë¹„êµì¸ì§€, ë‹¤ë¥¸ ë³€ìˆ˜ë“¤ì„ í†µì œí•œ ë¹„êµì¸ì§€ ë¶ˆë¶„ëª…",
                "ë¶„ì‚°ì˜ ë™ì§ˆì„±ì´ë‚˜ ì •ê·œì„± ê°€ì •ì— ëŒ€í•œ ê³ ë ¤ í•„ìš”"
            ],
            "clarification_questions": [
                "ì£¼ë¡œ ë¹„êµí•˜ê³  ì‹¶ì€ ê²°ê³¼ ë³€ìˆ˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”? (ì ìˆ˜, ë§Œì¡±ë„, ê²½í—˜ë…„ìˆ˜ ë“±)",
                "ë‹¨ìˆœí•œ ê·¸ë£¹ ê°„ ë¹„êµì¸ê°€ìš”, ì•„ë‹ˆë©´ ë‚˜ì´ë‚˜ ì„±ë³„ ë“±ì„ ê³ ë ¤í•œ ë¶„ì„ì¸ê°€ìš”?",
                "í†µê³„ì  ìœ ì˜ì„±ê³¼ í•¨ê»˜ ì‹¤ë¬´ì  ì˜ë¯¸ë„ ì¤‘ìš”í•œê°€ìš”?"
            ],
            "data_compatibility": {
                "available_variables": "ê·¸ë£¹(A,B,C), ì ìˆ˜, ë§Œì¡±ë„, ê²½í—˜ë…„ìˆ˜, ë‚˜ì´, ì„±ë³„",
                "missing_variables": "ì—†ìŒ",
                "preprocessing_needs": [
                    "ê·¸ë£¹ ë³€ìˆ˜ ë²”ì£¼í˜• í™•ì¸",
                    "ì—°ì†í˜• ë³€ìˆ˜ë“¤ì˜ ì •ê·œì„± ê²€ì •",
                    "ì´ìƒì¹˜ í™•ì¸"
                ]
            },
            "next_steps": [
                "ì‚¬ìš©ìì—ê²Œ ë¶„ì„ ëª©í‘œ í™•ì¸ ìš”ì²­",
                "ì„ íƒëœ ë¶„ì„ ë°©ë²•ì— ë”°ë¥¸ ë°ì´í„° ì „ì²˜ë¦¬",
                "í†µê³„ì  ê°€ì • ê²€í† "
            ],
            "overall_confidence": 0.75,
            "reasoning": "ê·¸ë£¹ê³¼ ì—°ì†í˜• ë³€ìˆ˜ê°€ ëª…í™•íˆ ìˆì–´ ë¶„ì„ ê°€ëŠ¥í•˜ì§€ë§Œ, êµ¬ì²´ì ì¸ ë¶„ì„ ëª©ì  ëª…í™•í™” í•„ìš”"
        }
        ```
        """
    
    def _generate_confirmation_response(self) -> str:
        """1-2 ë‹¨ê³„: ì‚¬ìš©ì ì„ íƒ í™•ì¸"""
        return """
        ## ë¶„ì„ ëª©í‘œ í™•ì¸ ìš”ì²­

        ```json
        {
            "action": "í™•ì¸",
            "content": "ì‚¬ìš©ìì˜ ë¶„ì„ ëª©í‘œ ì„ íƒì„ ìš”ì²­í•©ë‹ˆë‹¤",
            "user_selection": {
                "selected_option": 1,
                "confirmed": true,
                "modifications_requested": [],
                "additional_clarifications": [],
                "user_feedback": "ì²« ë²ˆì§¸ ì˜µì…˜(ê·¸ë£¹ë³„ ì ìˆ˜ í‰ê·  ë¹„êµ)ì„ ì„ íƒí•©ë‹ˆë‹¤"
            },
            "final_analysis_plan": {
                "analysis_goal": "ê·¸ë£¹ë³„ ì ìˆ˜ í‰ê·  ë¹„êµ ë¶„ì„",
                "analysis_type": "One-way ANOVA",
                "dependent_variable": "ì ìˆ˜",
                "independent_variable": "ê·¸ë£¹",
                "hypothesis": "ê·€ë¬´ê°€ì„¤: ëª¨ë“  ê·¸ë£¹ì˜ ì ìˆ˜ í‰ê· ì´ ê°™ë‹¤ vs ëŒ€ë¦½ê°€ì„¤: ì ì–´ë„ í•˜ë‚˜ì˜ ê·¸ë£¹ í‰ê· ì´ ë‹¤ë¥´ë‹¤",
                "confidence": 0.85
            },
            "next_steps": [
                "í™•ì •ëœ ë¶„ì„ ê³„íšìœ¼ë¡œ ë°ì´í„° ë¶„ì„ ì§„í–‰",
                "ë…ë¦½ì„± ì „ì œ ê²€í† ",
                "ë°ì´í„° ë¡œë”© ë° íƒìƒ‰"
            ],
            "confidence": 0.9,
            "reasoning": "ì‚¬ìš©ìê°€ ëª…í™•í•œ ì„ íƒì„ í–ˆìœ¼ë¯€ë¡œ ë¶„ì„ ì§„í–‰ ê°€ëŠ¥"
        }
        ```
        """
    
    def _generate_data_loading_response(self) -> str:
        """2-1 ë‹¨ê³„: ë°ì´í„° ë¡œë”© ì‘ë‹µ"""
        return """
        ```json
        {
            "action": "ë°ì´í„°_ë¡œë”©_ì™„ë£Œ",
            "content": "ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë”©ë˜ì—ˆìŠµë‹ˆë‹¤",
            "data_summary": {
                "total_rows": 20,
                "total_columns": 7,
                "missing_values": 0,
                "data_types": "ì •ìƒ"
            },
            "confidence": 1.0,
            "reasoning": "ë°ì´í„° ë¡œë”©ì— ë¬¸ì œì—†ìŒ"
        }
        ```
        """
    
    def _generate_variable_type_response(self) -> str:
        """2-2 ë‹¨ê³„: ë³€ìˆ˜ íƒ€ì… ì‹ë³„ ì‘ë‹µ"""
        return """
        ```json
        {
            "action": "ë³€ìˆ˜_ë¶„ì„_ì™„ë£Œ",
            "content": "ë³€ìˆ˜ íƒ€ì… ì‹ë³„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤",
            "variable_analysis": {
                "continuous_variables": [
                    {"name": "ì ìˆ˜", "description": "ì—°ì†í˜• ì ìˆ˜ ë³€ìˆ˜"},
                    {"name": "ë‚˜ì´", "description": "ì—°ì†í˜• ë‚˜ì´ ë³€ìˆ˜"},
                    {"name": "ê²½í—˜ë…„ìˆ˜", "description": "ì—°ì†í˜• ê²½í—˜ ë³€ìˆ˜"}
                ],
                "categorical_variables": [
                    {"name": "ê·¸ë£¹", "categories": ["A", "B", "C"]},
                    {"name": "ì„±ë³„", "categories": ["ë‚¨", "ì—¬"]}
                ],
                "ordinal_variables": [
                    {"name": "ë§Œì¡±ë„", "description": "1-5 ì²™ë„"}
                ],
                "identifier_variables": [
                    {"name": "ID", "recommendation": "ë¶„ì„ì—ì„œ ì œì™¸"}
                ]
            },
            "confidence": 0.95,
            "reasoning": "ëª…í™•í•œ ë³€ìˆ˜ íƒ€ì… ë¶„ë¥˜ ì™„ë£Œ"
        }
        ```
        """

def test_enhanced_query_mode():
    """ê°œì„ ëœ ìì—°ì–´ ìš”ì²­ ëª¨ë“œ ì¢…í•© í…ŒìŠ¤íŠ¸"""
    print("ğŸ”¬ ê°œì„ ëœ ìì—°ì–´ ìš”ì²­ ëª¨ë“œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    try:
        # í•„ìš”í•œ ëª¨ë“ˆ ì„í¬íŠ¸
        from core.workflow_manager import WorkflowManager
        from core.decision_engine import DecisionEngine
        from core.context_manager import ContextManager
        from llm_services.prompt_crafter import PromptCrafter
        from data_processing.data_loader import DataLoader
        from rag_system.code_retriever import CodeRetriever
        from code_execution.safe_code_executor import SafeCodeExecutor
        from reporting.report_generator import ReportGenerator
        from core.agent import LLMAgent
        
        # Mock LLM í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        mock_llm = MockLLMClient()
        
        # ê° ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        workflow_manager = WorkflowManager("resources/workflow_graph.json")
        decision_engine = DecisionEngine()
        context_manager = ContextManager(mock_llm)
        prompt_crafter = PromptCrafter("llm_services/prompts")
        data_loader = DataLoader()
        code_retriever = CodeRetriever("resources/code_snippets")
        safe_code_executor = SafeCodeExecutor()
        report_generator = ReportGenerator("output_results")
        
        # LLM Agent ìƒì„± 
        agent = LLMAgent(
            workflow_manager=workflow_manager,
            decision_engine=decision_engine,
            context_manager=context_manager,
            llm_client=mock_llm,
            prompt_crafter=prompt_crafter,
            data_loader=data_loader,
            code_retriever=code_retriever,
            safe_code_executor=safe_code_executor,
            report_generator=report_generator
        )
        
        print("âœ… ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
        
        # í…ŒìŠ¤íŠ¸ 1: ëª¨í˜¸í•œ ìì—°ì–´ ìš”ì²­ìœ¼ë¡œ ì‹œì‘
        print("\nğŸ§ª í…ŒìŠ¤íŠ¸ 1: ëª¨í˜¸í•œ ìì—°ì–´ ìš”ì²­ ì²˜ë¦¬")
        test_query = "ê·¸ë£¹ë³„ í‰ê·  ì°¨ì´ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”"
        print(f"ì…ë ¥ ì¿¼ë¦¬: '{test_query}'")
        
        # ì‹œì‘ ë…¸ë“œ ê²°ì • í…ŒìŠ¤íŠ¸
        initial_node = agent._determine_initial_node(test_query)
        print(f"ê²°ì •ëœ ì‹œì‘ ë…¸ë“œ: {initial_node}")
        assert initial_node == "1-1", f"ì˜ˆìƒ: 1-1, ì‹¤ì œ: {initial_node}"
        print("âœ… ìì—°ì–´ ìš”ì²­ ì‹œ ì˜¬ë°”ë¥¸ ì‹œì‘ ë…¸ë“œ ì„ íƒ")
        
        # ì‚¬ìš©ì ìš”ì²­ ì €ì¥ í…ŒìŠ¤íŠ¸
        agent.analysis_parameters['user_request'] = test_query
        print(f"ì €ì¥ëœ ì‚¬ìš©ì ìš”ì²­: {agent.analysis_parameters.get('user_request')}")
        assert agent.analysis_parameters['user_request'] == test_query
        print("âœ… ì‚¬ìš©ì ìš”ì²­ ì €ì¥ ì„±ê³µ")
        
        # í…ŒìŠ¤íŠ¸ 2: ë°ì´í„° ë¡œë”© ë° ê¸°ë³¸ ì •ë³´ í™•ì¸
        print("\nğŸ§ª í…ŒìŠ¤íŠ¸ 2: ë°ì´í„° ë¡œë”© ë° ë¶„ì„")
        data_path = "input_data/sample_survey_data.csv"
        
        if os.path.exists(data_path):
            agent._load_initial_data(data_path)
            print(f"ë°ì´í„° í˜•íƒœ: {agent.raw_data.shape}")
            print(f"ë°ì´í„° ì»¬ëŸ¼: {list(agent.raw_data.columns)}")
            
            # ë°ì´í„° ìš”ì•½ í…ŒìŠ¤íŠ¸
            data_summary = agent._get_data_summary()
            print(f"ë°ì´í„° ìš”ì•½: {data_summary}")
            print("âœ… ë°ì´í„° ë¡œë”© ë° ìš”ì•½ ì„±ê³µ")
        else:
            print(f"âš ï¸ í…ŒìŠ¤íŠ¸ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {data_path}")
        
        # í…ŒìŠ¤íŠ¸ 3: 1-1 ë…¸ë“œ í”„ë¡¬í”„íŠ¸ ìƒì„± ë° LLM ì‘ë‹µ ì²˜ë¦¬
        print("\nğŸ§ª í…ŒìŠ¤íŠ¸ 3: 1-1 ë‹¨ê³„ - ì‚¬ìš©ì ìš”ì²­ ë¶„ì„")
        agent.current_node_id = "1-1"
        
        # ë™ì  ë°ì´í„° ì¤€ë¹„
        dynamic_data = {
            'node_id': agent.current_node_id,
            'user_request': test_query,
            'data_summary': agent._get_data_summary() if agent.raw_data is not None else None,
            'analysis_parameters': agent.analysis_parameters
        }
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸
        try:
            prompt = prompt_crafter.get_prompt_for_node(
                node_id="1-1", 
                dynamic_data=dynamic_data,
                agent_context_summary="í…ŒìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸"
            )
            print("âœ… 1-1 ë‹¨ê³„ í”„ë¡¬í”„íŠ¸ ìƒì„± ì„±ê³µ")
            print(f"í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ë¬¸ì")
            
            # Mock LLM ì‘ë‹µ ì²˜ë¦¬
            response = mock_llm.generate_text(prompt)
            agent._update_analysis_parameters_from_response(response)
            
            print("âœ… LLM ì‘ë‹µ ì²˜ë¦¬ ì„±ê³µ")
            print(f"ë¶„ì„ í›„ë³´ ê°œìˆ˜: {len(agent.analysis_parameters.get('analysis_candidates', []))}")
            print(f"ë¶ˆí™•ì‹¤ ì˜ì—­ ê°œìˆ˜: {len(agent.analysis_parameters.get('uncertainty_areas', []))}")
            
        except Exception as e:
            print(f"âŒ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        
        # í…ŒìŠ¤íŠ¸ 4: 1-2 ë…¸ë“œ ë‹¤ì¤‘ í›„ë³´ ì²˜ë¦¬
        print("\nğŸ§ª í…ŒìŠ¤íŠ¸ 4: 1-2 ë‹¨ê³„ - ë‹¤ì¤‘ í›„ë³´ í™•ì¸")
        agent.current_node_id = "1-2"
        
        # 1-2 ë‹¨ê³„ìš© ë™ì  ë°ì´í„° ì¤€ë¹„
        dynamic_data_1_2 = {
            'node_id': agent.current_node_id,
            'user_request': test_query,
            'analysis_candidates': agent.analysis_parameters.get('analysis_candidates', []),
            'uncertainty_areas': agent.analysis_parameters.get('uncertainty_areas', []),
            'clarification_questions': agent.analysis_parameters.get('clarification_questions', []),
            'data_compatibility': agent.analysis_parameters.get('data_compatibility', {})
        }
        
        try:
            prompt_1_2 = prompt_crafter.get_prompt_for_node(
                node_id="1-2",
                dynamic_data=dynamic_data_1_2,
                agent_context_summary="ì´ì „ ë¶„ì„ ê²°ê³¼"
            )
            print("âœ… 1-2 ë‹¨ê³„ í”„ë¡¬í”„íŠ¸ ìƒì„± ì„±ê³µ")
            
            # Mock ì‚¬ìš©ì ì„ íƒ ì²˜ë¦¬
            response_1_2 = mock_llm.generate_text(prompt_1_2)
            agent._update_analysis_parameters_from_response(response_1_2)
            
            print("âœ… ì‚¬ìš©ì ì„ íƒ í™•ì • ì²˜ë¦¬ ì„±ê³µ")
            print(f"í™•ì •ëœ ë¶„ì„ ëª©í‘œ: {agent.analysis_parameters.get('confirmed_analysis_goal')}")
            print(f"í™•ì •ëœ ë¶„ì„ ë°©ë²•: {agent.analysis_parameters.get('confirmed_analysis_type')}")
            
        except Exception as e:
            print(f"âŒ 1-2 ë‹¨ê³„ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        
        # í…ŒìŠ¤íŠ¸ 5: í•„ìˆ˜ ë³€ìˆ˜ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
        print("\nğŸ§ª í…ŒìŠ¤íŠ¸ 5: í•„ìˆ˜ ë³€ìˆ˜ ì¶”ì¶œ")
        required_vars = agent._get_required_variables()
        print(f"ì¶”ì¶œëœ í•„ìˆ˜ ë³€ìˆ˜: {required_vars}")
        print("âœ… ë³€ìˆ˜ ì¶”ì¶œ ì„±ê³µ")
        
        # ì¢…í•© ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 60)
        print("ğŸ‰ ì¢…í•© í…ŒìŠ¤íŠ¸ ê²°ê³¼")
        print("=" * 60)
        
        print(f"âœ… Mock LLM í˜¸ì¶œ íšŸìˆ˜: {mock_llm.call_count}")
        print(f"âœ… ì €ì¥ëœ ë¶„ì„ íŒŒë¼ë¯¸í„° ê°œìˆ˜: {len(agent.analysis_parameters)}")
        print(f"âœ… ì²˜ë¦¬ëœ ë¶„ì„ í›„ë³´: {len(agent.analysis_parameters.get('analysis_candidates', []))}ê°œ")
        
        # ì£¼ìš” ë¶„ì„ íŒŒë¼ë¯¸í„° ì¶œë ¥
        if 'analysis_candidates' in agent.analysis_parameters:
            print("\nğŸ“Š 1ìˆœìœ„ ë¶„ì„ í›„ë³´:")
            primary = agent.analysis_parameters['analysis_candidates'][0]
            print(f"  - ëª©í‘œ: {primary['analysis_goal']}")
            print(f"  - ë°©ë²•: {primary['analysis_type']}")
            print(f"  - ì¢…ì†ë³€ìˆ˜: {primary['dependent_variable']}")
            print(f"  - ë…ë¦½ë³€ìˆ˜: {primary['independent_variable']}")
            print(f"  - í™•ì‹ ë„: {primary['confidence']}")
        
        if agent.analysis_parameters.get('uncertainty_areas'):
            print(f"\nâ“ ì‹ë³„ëœ ë¶ˆí™•ì‹¤ ì˜ì—­: {len(agent.analysis_parameters['uncertainty_areas'])}ê°œ")
            for i, area in enumerate(agent.analysis_parameters['uncertainty_areas'][:2], 1):
                print(f"  {i}. {area}")
        
        print("\nğŸ¯ ê²°ë¡ : ê°œì„ ëœ ëª¨í˜¸í•œ ìì—°ì–´ ìš”ì²­ ì²˜ë¦¬ ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™í•¨")
        print("   - ë‹¤ì¤‘ í•´ì„ í›„ë³´ ì œì‹œ âœ…")
        print("   - ë¶ˆí™•ì‹¤ì„± ëª…ì‹œì  ì²˜ë¦¬ âœ…") 
        print("   - ë‹¨ê³„ë³„ ë°ì´í„° ì „ë‹¬ âœ…")
        print("   - JSON êµ¬ì¡° íŒŒì‹± âœ…")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("ğŸš€ TEXT_TO_STATISTICAL_TEST ê°œì„ ëœ ìì—°ì–´ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
    print(f"í…ŒìŠ¤íŠ¸ ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    success = test_enhanced_query_mode()
    
    if success:
        print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! ì‹œìŠ¤í…œì´ ëª¨í˜¸í•œ ìì—°ì–´ ìš”ì²­ì„ íš¨ê³¼ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        exit_code = 0
    else:
        print("\nâŒ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ì‹œìŠ¤í…œ ì ê²€ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        exit_code = 1
    
    print(f"í…ŒìŠ¤íŠ¸ ì¢…ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    exit(exit_code) 